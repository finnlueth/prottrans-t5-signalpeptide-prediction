{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.config\n",
    "import src.data\n",
    "import src.model_new\n",
    "import src.utils\n",
    "from src.model_new import (\n",
    "    T5EncoderModelForTokenClassification,\n",
    ")\n",
    "\n",
    "import gc\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import src.utils\n",
    "\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback\n",
    ")\n",
    "\n",
    "import peft\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model:\t Rostlab/prot_t5_xl_uniref50\n",
      "MPS:\t\t False\n",
      "Path:\t\t /home/ec2-user/developer/prottrans-t5-signalpeptide-prediction\n",
      "Using device:\t cuda:0\n"
     ]
    }
   ],
   "source": [
    "ROOT = src.utils.get_project_root_path()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Base Model:\\t\", src.config.base_model_name)\n",
    "print(\"MPS:\\t\\t\", torch.backends.mps.is_available())\n",
    "print(\"Path:\\t\\t\", ROOT)\n",
    "print(f\"Using device:\\t {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=src.config.base_model_name,\n",
    "    do_lower_case=False,\n",
    "    use_fast=True,\n",
    "    legacy=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTA_FILENAME = '5_SignalP_5.0_Training_set.fasta'\n",
    "# FASTA_FILENAME = '5_SignalP_5.0_Training_set_testing.fasta'\n",
    "annotations_name = 'Label' # Choose Type or Label\n",
    "\n",
    "df_data = src.data.process(src.data.parse_file(ROOT + '/data/raw/' + FASTA_FILENAME))\n",
    "\n",
    "dataset_signalp_type_splits = {}\n",
    "\n",
    "for sequence_type in src.config.type_encoding.keys():\n",
    "    dataset_signalp = src.model_new.create_datasets(\n",
    "        splits=src.config.splits,\n",
    "        tokenizer=t5_tokenizer,\n",
    "        data=df_data,\n",
    "        annotations_name=annotations_name,\n",
    "        dataset_size=src.config.dataset_size,\n",
    "        # dataset_size=3,\n",
    "        encoder=src.config.select_encoding_type[sequence_type],\n",
    "        sequence_type=sequence_type\n",
    "        )\n",
    "    dataset_signalp_type_splits.update({sequence_type: dataset_signalp})\n",
    "\n",
    "del df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2017\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 679\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 676\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_signalp_type_splits\n",
    "# dataset_signalp_type_splits['TAT']['train'][200]['labels']\n",
    "\n",
    "expert = 'SP'\n",
    "dataset_signalp = dataset_signalp_type_splits[expert]\n",
    "# len(src.config.select_decoding_type[expert])\n",
    "dataset_signalp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5EncoderModelForTokenClassification were not initialized from the model checkpoint at Rostlab/prot_t5_xl_uniref50 and are newly initialized: ['custom_classifier.bias', 'custom_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "t5_base_model = T5EncoderModelForTokenClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=src.config.base_model_name,\n",
    "    device_map='auto',\n",
    "    load_in_8bit=False,\n",
    "    custom_num_labels=len(src.config.select_decoding_type[expert]),\n",
    "    custom_dropout_rate=0.1,\n",
    ")\n",
    "\n",
    "t5_base_model.custom_classifier.weight = nn.Linear(\n",
    "in_features=t5_base_model.config.hidden_size,\n",
    "out_features=t5_base_model.custom_num_labels).weight\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=['q', 'k', 'v', 'o'],\n",
    "    bias=\"none\",\n",
    "    modules_to_save=['custom_classifier'],\n",
    ")\n",
    "\n",
    "t5_lora_model = peft.get_peft_model(t5_base_model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in t5_lora_model.custom_classifier.modules_to_save.default.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=t5_tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./checkpoints',\n",
    "    learning_rate=src.config.lr,\n",
    "    per_device_train_batch_size=src.config.batch_size,\n",
    "    per_device_eval_batch_size=src.config.batch_size,\n",
    "    num_train_epochs=src.config.num_epochs,\n",
    "    logging_steps=src.config.logging_steps,\n",
    "    # save_strategy=\"steps\",\n",
    "    # save_steps=src.config.save_steps,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # eval_steps=src.config.eval_steps,\n",
    "    # gradient_accumulation_steps=accum,\n",
    "    # load_best_model_at_end=True,\n",
    "    # save_total_limit=5,\n",
    "    seed=42,\n",
    "    # fp16=True,\n",
    "    # deepspeed=deepspeed_config,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=['labels'],\n",
    "    # debug=\"underflow_overflow\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=t5_lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_signalp['train'],\n",
    "    eval_dataset=dataset_signalp['valid'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=src.model_new.compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(2.3890, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='127' max='127' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [127/127 03:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.151600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.189600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.134400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.128800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.100400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.135300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.193000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.095800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.126900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.116400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13236996165668426339057664.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.056700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.083200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.132900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.054700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>43020237538422385601937408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>46329486579839492186701824.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.064500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>69494225258073219852664832.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>26473992331336852678115328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>3309249041417106584764416.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.074500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.087800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.128300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.088300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.059100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>56257233704090811940995072.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.049300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.033700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>86040475076844771203874816.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.024900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>93074476846567255168778240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.041400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.046400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.074700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.084900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>95968217589410072530780160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>33092488108328056633950208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.046200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.079900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.052600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>9954410739888362304307200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.041900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.031400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>39710988497005279017172992.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.081100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>13514526277335881936273408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>36401737149745163218714624.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.063300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.051900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.030400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.046600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>82879219651445017924337664.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.039800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.141600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>13236996165668426339057664.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>105895969325347410712461312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.043800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.045500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.073700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>36895879306619657832628224.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.040900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.029400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>43020237538422385601937408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.025200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.049900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.051500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.040100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.104800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>20439478966545127279951872.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.042300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.045200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.046200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>72803474299490326437429248.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(2.4704, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(2.5920, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(2.7118, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(2.6808, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(2.8283, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(2.7584, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(2.8884, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(2.9568, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(2.9110, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(2.9457, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.0599, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.0972, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.0757, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.1550, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.0968, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.2732, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.2010, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.3281, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.4184, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.3208, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.3375, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.3754, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.4713, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.4779, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5252, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5216, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5422, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5357, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.4728, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5391, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5466, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5608, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5069, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6420, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6784, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5853, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5945, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6071, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5636, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5702, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5621, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6017, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6801, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7022, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6061, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7531, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6362, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.5544, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6237, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6235, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6768, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6473, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6351, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7504, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6112, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7030, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7473, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6626, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7228, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6927, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6406, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7710, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7745, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6825, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7363, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7507, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.6997, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8002, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9740, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7688, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7303, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7563, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8803, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7760, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8623, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8721, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9645, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7804, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7666, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8152, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8434, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8877, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8330, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9232, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8370, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9150, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8400, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9083, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8555, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7798, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8953, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9385, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9013, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9209, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8591, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8295, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7816, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8697, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8278, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9084, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8312, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8014, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9573, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9125, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8816, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9249, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8480, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8311, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1004, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8943, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9194, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8369, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9816, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8940, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8422, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8373, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9139, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8235, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8240, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9875, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.8103, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9282, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(4.1050, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9778, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.9475, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(3.7861, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=127, training_loss=8.197244064232373e+24, metrics={'train_runtime': 183.5905, 'train_samples_per_second': 10.986, 'train_steps_per_second': 0.692, 'total_flos': 1041358417513296.0, 'train_loss': 8.197244064232373e+24, 'epoch': 1.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0292,  0.0260, -0.0024,  ..., -0.0158, -0.0303, -0.0182],\n",
       "          [ 0.0102, -0.0044,  0.0047,  ...,  0.0020,  0.0037,  0.0288],\n",
       "          [ 0.0216,  0.0068,  0.0021,  ...,  0.0116, -0.0260,  0.0228],\n",
       "          [-0.0139,  0.0027, -0.0077,  ...,  0.0118, -0.0120, -0.0072]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([-3.7064e+27, -6.1088e-03,  5.8706e-03,  4.9565e-04], device='cuda:0',\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in t5_lora_model.custom_classifier.modules_to_save.default.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8711, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8564, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8355, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.9093, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8351, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8806, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8484, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8927, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8984, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8719, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8829, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8656, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8583, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8607, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8551, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8376, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8996, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8733, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8430, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8571, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.7985, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8285, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8277, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8787, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8782, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8610, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8802, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8502, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8462, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8511, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8294, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8574, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8071, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.9391, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8317, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8549, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8736, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8621, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8559, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8825, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8454, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.8408, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "logits tensor([[-3.7064e+27, -1.9119e+00, -2.0388e+00,  3.6185e+00],\n",
      "        [-3.7064e+27, -1.8949e+00, -1.8902e+00,  3.5277e+00],\n",
      "        [-3.7064e+27, -1.9497e+00, -1.8584e+00,  3.4481e+00],\n",
      "        ...,\n",
      "        [-3.7064e+27, -1.4512e+00,  3.3402e+00, -2.3440e+00],\n",
      "        [-3.7064e+27, -1.4562e+00,  3.2582e+00, -2.3590e+00],\n",
      "        [-3.7064e+27, -3.4888e-01,  1.1474e+00, -1.0246e+00]], device='cuda:0')\n",
      "labels tensor([   3,    3,    3,  ...,    2,    2, -100], device='cuda:0')\n",
      "tensor(2.2503e+26, device='cuda:0')\n",
      "tensor(-3.7064e+27, device='cuda:0') tensor(3.6945, device='cuda:0')\n",
      "tensor(False, device='cuda:0')\n",
      "logits tensor([[-3.7064e+27, -1.8255e+00, -2.0276e+00,  3.6258e+00],\n",
      "        [-3.7064e+27, -1.8602e+00, -1.9828e+00,  3.4787e+00],\n",
      "        [-3.7064e+27, -1.8345e+00, -2.0017e+00,  3.4593e+00],\n",
      "        ...,\n",
      "        [-3.7064e+27, -8.9341e-01,  2.0842e+00, -1.6048e+00],\n",
      "        [-3.7064e+27, -8.4232e-01,  2.0663e+00, -1.5445e+00],\n",
      "        [-3.7064e+27, -2.7111e-02,  2.4191e-01, -2.3938e-01]], device='cuda:0')\n",
      "labels tensor([   3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    2,    2,    2,    1, -100,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    2,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2,    2,    2,    2, -100,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    2,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1, -100,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    2,    2,    2,    2,    2,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    1,    1,    1,    1,    1,    2,\n",
      "           2,    2,    2,    2,    1,    1,    1,    1,    1,    1,    1,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0, -100,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2, -100,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    2,    2,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2, -100,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    2,    2,    2,    2,    2,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    0,    0,    0,    0,    0,    0,    0,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    2,    2,    2,    2,    2,\n",
      "           2,    2,    2,    2,    2,    2,    2,    2,    1,    1,    1,    1,\n",
      "           0,    0,    0,    0, -100], device='cuda:0')\n",
      "tensor(2.9500e+26, device='cuda:0')\n",
      "{'eval_loss': 8.343790350706891e+24, 'eval_accuracy_metric': 0.9840548520648867, 'eval_precision_metric': 0.9840548520648867, 'eval_recall_metric': 0.9840548520648867, 'eval_f1_metric': 0.9840548520648867, 'eval_matthews_correlation': 0.9743977825029082, 'eval_confusion_matrix': array([[    0,     0,     0,     0],\n",
      "       [    0,     0,     0,     0],\n",
      "       [  107,   207, 30770,   267],\n",
      "       [    0,     0,   163, 15785]]), 'eval_runtime': 43.2723, 'eval_samples_per_second': 15.691, 'eval_steps_per_second': 0.994, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "metrics=trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_metric</th>\n",
       "      <th>eval_precision_metric</th>\n",
       "      <th>eval_recall_metric</th>\n",
       "      <th>eval_f1_metric</th>\n",
       "      <th>eval_matthews_correlation</th>\n",
       "      <th>eval_confusion_matrix</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.516000e-01</td>\n",
       "      <td>9.921260e-05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.896000e-01</td>\n",
       "      <td>9.842520e-05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.344000e-01</td>\n",
       "      <td>9.763780e-05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.288000e-01</td>\n",
       "      <td>9.685039e-05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.004000e-01</td>\n",
       "      <td>9.606299e-05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>7.280347e+25</td>\n",
       "      <td>1.574803e-06</td>\n",
       "      <td>0.98</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2.310000e-02</td>\n",
       "      <td>7.874016e-07</td>\n",
       "      <td>0.99</td>\n",
       "      <td>126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.520000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>127</td>\n",
       "      <td>183.5905</td>\n",
       "      <td>10.986</td>\n",
       "      <td>0.692</td>\n",
       "      <td>1.041358e+15</td>\n",
       "      <td>8.197244e+24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.343790e+24</td>\n",
       "      <td>0.984055</td>\n",
       "      <td>0.984055</td>\n",
       "      <td>0.984055</td>\n",
       "      <td>0.984055</td>\n",
       "      <td>0.974398</td>\n",
       "      <td>[[0, 0, 0, 0], [0, 0, 0, 0], [107, 207, 30770,...</td>\n",
       "      <td>43.2723</td>\n",
       "      <td>15.691</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             loss  learning_rate  epoch  step  train_runtime  \\\n",
       "0    1.516000e-01   9.921260e-05   0.01     1            NaN   \n",
       "1    1.896000e-01   9.842520e-05   0.02     2            NaN   \n",
       "2    1.344000e-01   9.763780e-05   0.02     3            NaN   \n",
       "3    1.288000e-01   9.685039e-05   0.03     4            NaN   \n",
       "4    1.004000e-01   9.606299e-05   0.04     5            NaN   \n",
       "..            ...            ...    ...   ...            ...   \n",
       "124  7.280347e+25   1.574803e-06   0.98   125            NaN   \n",
       "125  2.310000e-02   7.874016e-07   0.99   126            NaN   \n",
       "126  1.520000e-02   0.000000e+00   1.00   127            NaN   \n",
       "127           NaN            NaN   1.00   127       183.5905   \n",
       "128           NaN            NaN   1.00   127            NaN   \n",
       "\n",
       "     train_samples_per_second  train_steps_per_second    total_flos  \\\n",
       "0                         NaN                     NaN           NaN   \n",
       "1                         NaN                     NaN           NaN   \n",
       "2                         NaN                     NaN           NaN   \n",
       "3                         NaN                     NaN           NaN   \n",
       "4                         NaN                     NaN           NaN   \n",
       "..                        ...                     ...           ...   \n",
       "124                       NaN                     NaN           NaN   \n",
       "125                       NaN                     NaN           NaN   \n",
       "126                       NaN                     NaN           NaN   \n",
       "127                    10.986                   0.692  1.041358e+15   \n",
       "128                       NaN                     NaN           NaN   \n",
       "\n",
       "       train_loss     eval_loss  eval_accuracy_metric  eval_precision_metric  \\\n",
       "0             NaN           NaN                   NaN                    NaN   \n",
       "1             NaN           NaN                   NaN                    NaN   \n",
       "2             NaN           NaN                   NaN                    NaN   \n",
       "3             NaN           NaN                   NaN                    NaN   \n",
       "4             NaN           NaN                   NaN                    NaN   \n",
       "..            ...           ...                   ...                    ...   \n",
       "124           NaN           NaN                   NaN                    NaN   \n",
       "125           NaN           NaN                   NaN                    NaN   \n",
       "126           NaN           NaN                   NaN                    NaN   \n",
       "127  8.197244e+24           NaN                   NaN                    NaN   \n",
       "128           NaN  8.343790e+24              0.984055               0.984055   \n",
       "\n",
       "     eval_recall_metric  eval_f1_metric  eval_matthews_correlation  \\\n",
       "0                   NaN             NaN                        NaN   \n",
       "1                   NaN             NaN                        NaN   \n",
       "2                   NaN             NaN                        NaN   \n",
       "3                   NaN             NaN                        NaN   \n",
       "4                   NaN             NaN                        NaN   \n",
       "..                  ...             ...                        ...   \n",
       "124                 NaN             NaN                        NaN   \n",
       "125                 NaN             NaN                        NaN   \n",
       "126                 NaN             NaN                        NaN   \n",
       "127                 NaN             NaN                        NaN   \n",
       "128            0.984055        0.984055                   0.974398   \n",
       "\n",
       "                                 eval_confusion_matrix  eval_runtime  \\\n",
       "0                                                  NaN           NaN   \n",
       "1                                                  NaN           NaN   \n",
       "2                                                  NaN           NaN   \n",
       "3                                                  NaN           NaN   \n",
       "4                                                  NaN           NaN   \n",
       "..                                                 ...           ...   \n",
       "124                                                NaN           NaN   \n",
       "125                                                NaN           NaN   \n",
       "126                                                NaN           NaN   \n",
       "127                                                NaN           NaN   \n",
       "128  [[0, 0, 0, 0], [0, 0, 0, 0], [107, 207, 30770,...       43.2723   \n",
       "\n",
       "     eval_samples_per_second  eval_steps_per_second  \n",
       "0                        NaN                    NaN  \n",
       "1                        NaN                    NaN  \n",
       "2                        NaN                    NaN  \n",
       "3                        NaN                    NaN  \n",
       "4                        NaN                    NaN  \n",
       "..                       ...                    ...  \n",
       "124                      NaN                    NaN  \n",
       "125                      NaN                    NaN  \n",
       "126                      NaN                    NaN  \n",
       "127                      NaN                    NaN  \n",
       "128                   15.691                  0.994  \n",
       "\n",
       "[129 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_log = pd.DataFrame(trainer.state.log_history)\n",
    "display(training_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0],\n",
       "       [    0,     0,     0,     0],\n",
       "       [  107,   207, 30770,   267],\n",
       "       [    0,     0,   163, 15785]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_log['eval_confusion_matrix'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    92502\n",
       "3    47167\n",
       "1      617\n",
       "0      314\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    30933\n",
       "3    16052\n",
       "1      207\n",
       "0      107\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2    31236\n",
       "3    15677\n",
       "1      112\n",
       "0      100\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.Series([item for row in dataset_signalp['train']['labels'] for item in row]).value_counts())\n",
    "display(pd.Series([item for row in dataset_signalp['valid']['labels'] for item in row]).value_counts())\n",
    "display(pd.Series([item for row in dataset_signalp['test']['labels'] for item in row]).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'I', 1: 'M', 2: 'O', 3: 'S'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Confusion Matrix'}, xlabel='Actual', ylabel='Predicted'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src.model_new.make_confusion_matrix(\n",
    "    training_log['eval_confusion_matrix'].iloc[-1],\n",
    "    src.config.select_decoding_type[expert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log = pd.DataFrame(trainer.state.log_history)\n",
    "if 'eval_confusion_matrix' in training_log.columns:\n",
    "    training_log['eval_confusion_matrix'] = training_log['eval_confusion_matrix'].apply(lambda x: x.tolist() if type(x)==np.ndarray else None)\n",
    "adapter_location = '/models/expert_testing_1/' + expert + '_expert/'\n",
    "t5_lora_model.save_pretrained(ROOT + adapter_location)\n",
    "training_log.to_csv(ROOT + adapter_location + '/training_log.csv', index=False)\n",
    "training_log.to_parquet(ROOT + adapter_location + '/training_log.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ds_index = 2\n",
    "_ds_type = 'test'\n",
    "\n",
    "_input_ids_test = t5_tokenizer.decode(dataset_signalp[_ds_type][_ds_index]['input_ids'])\n",
    "_labels_test = torch.tensor(dataset_signalp[_ds_type][_ds_index]['labels'] + [-100]).to(device)\n",
    "_attention_mask_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['attention_mask']]).to(device)\n",
    "\n",
    "_labels_test_decoded = [src.config.label_decoding[x] for x in _labels_test.tolist()[:-1]]\n",
    "print('Iput IDs:\\t', _input_ids_test)\n",
    "print('Labels:\\t\\t', *_labels_test.tolist())\n",
    "print('Labels Decoded:\\t', *_labels_test_decoded)\n",
    "print('Attention Mask:\\t', *_attention_mask_test.tolist()[0])\n",
    "print('----')\n",
    "\n",
    "preds = src.model_new.predict_model(\n",
    "    sequence=_input_ids_test,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    model=t5_lora_model,\n",
    "    labels=_labels_test,\n",
    "    attention_mask=_attention_mask_test,\n",
    "    device=device,\n",
    "    )\n",
    "\n",
    "_result = src.model_new.translate_logits(preds.logits.cpu().numpy())\n",
    "print('Result: \\t',* _result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
