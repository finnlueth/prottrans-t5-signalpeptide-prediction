{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup, Packages, Setup, and Variables\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/finnlueth/Developer/gits/prottrans-t5-signalpeptide-prediction/.venv/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import gc\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import types\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import (\n",
    "    CrossEntropyLoss,\n",
    "    MSELoss\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoConfig,\n",
    "    T5EncoderModel,\n",
    "    T5Tokenizer,\n",
    "    T5PreTrainedModel,\n",
    "    T5ForConditionalGeneration,\n",
    "    pipeline,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    "    EvalPrediction,\n",
    "    )\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    TaskType,\n",
    "    get_peft_config,\n",
    "    PeftModel,\n",
    "    PeftConfig,\n",
    "    prepare_model_for_kbit_training\n",
    "    )\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import src.config as config\n",
    "\n",
    "from src.model import (\n",
    "    get_prottrans_tokenizer_model,\n",
    "    df_to_dataset,\n",
    "    inject_linear_layer,\n",
    "    compute_metrics_fast\n",
    "    )\n",
    "from src.utils import get_project_root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model_name = config.base_model_name\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "ROOT = get_project_root_path()\n",
    "\n",
    "if config.VERBOSE:\n",
    "    print(\"Base Model:\\t\", base_model_name)\n",
    "    print(\"MPS:\\t\\t\", torch.backends.mps.is_available())\n",
    "    print(\"Path:\\t\\t\", ROOT)\n",
    "    print(f\"Using device:\\t {device}\")\n",
    "\n",
    "pd.set_option('display.max_colwidth',3000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Tokenizer and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_architecture = T5EncoderModel\n",
    "t5_tokenizer, t5_base_model = get_prottrans_tokenizer_model(base_model_name, model_architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence_example = 'MSLSRREFVKLCSAGVAGLGISQIY'\n",
    "# print(len(sequence_example))\n",
    "# sequence_example = \" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence_example)))\n",
    "\n",
    "# print(t5_tokenizer.decode([4, 7, 7, 10, 8, 1]))\n",
    "# print(t5_tokenizer.decode([4, 7, 7, 10, 8]))\n",
    "\n",
    "# t_tensor = torch.tensor([4, 7, 7, 10, 8, 1]).to('mps')\n",
    "# t_tensor = t_tensor.unsqueeze(0)\n",
    "# with torch.no_grad():\n",
    "#     res = t5_base_model(input_ids=t_tensor)\n",
    "# print(res)\n",
    "# print(res.last_hidden_state.argmax(-1))\n",
    "\n",
    "# t_tensor = torch.tensor([4, 7, 7, 10, 8]).to('mps')\n",
    "# t_tensor = t_tensor.unsqueeze(0)\n",
    "# with torch.no_grad():\n",
    "#     res = t5_base_model(input_ids=t_tensor)\n",
    "# print(res)\n",
    "# print(res.last_hidden_state.argmax(dim=-1))\n",
    "\n",
    "# tkns = t5_tokenizer.batch_encode_plus([sequence_example, sequence_example[::-1]], padding=True, return_tensors=\"pt\")\n",
    "# tkns.to(device)\n",
    "# print(tkns.input_ids)\n",
    "\n",
    "# print(tkns.input_ids.shape)\n",
    "# print(tkns.input_ids[0])\n",
    "# print(tkns.attention_mask[0][:-1].shape)\n",
    "\n",
    "# t_tensor_input = torch.tensor([[4, 7, 7, 12, 1, 1]]).to('mps')\n",
    "# t_tensor_mask = torch.tensor([[1, 1, 1, 1, 1, 0]]).to('mps')\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     res = t5_base_model(\n",
    "#         input_ids=t_tensor_input,\n",
    "#         attention_mask=t_tensor_mask,\n",
    "#         )\n",
    "# print(res.last_hidden_state.shape)\n",
    "# print(res.last_hidden_state.argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Data, Split into Dataset, and Tokenize Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_parquet(ROOT + '/data/processed/5.0_train.parquet.gzip')\n",
    "if config.VERBOSE:\n",
    "    df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/finnlueth/Developer/gits/prottrans-t5-signalpeptide-prediction/.venv/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/Users/finnlueth/Developer/gits/prottrans-t5-signalpeptide-prediction/.venv/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "ds_train = df_data[df_data.Split.isin([0, 1, 2])].head(config.dataset_size*3 if config.dataset_size else None)\n",
    "ds_train = df_to_dataset(\n",
    "    t5_tokenizer,\n",
    "    ds_train.Sequence.to_list(),\n",
    "    ds_train.Label.to_list(),\n",
    ")\n",
    "\n",
    "ds_validate = df_data[df_data.Split.isin([3])].head(config.dataset_size)\n",
    "ds_validate = df_to_dataset(\n",
    "    t5_tokenizer,\n",
    "    ds_validate.Sequence.to_list(),\n",
    "    ds_validate.Label.to_list(),\n",
    ")\n",
    "\n",
    "ds_test = df_data[df_data.Split.isin([4])].head(config.dataset_size)\n",
    "ds_test = df_to_dataset(\n",
    "    t5_tokenizer,\n",
    "    ds_test.Sequence.to_list(),\n",
    "    ds_test.Label.to_list()\n",
    ")\n",
    "\n",
    "dataset_signalp = DatasetDict({\n",
    "    'train': ds_train,\n",
    "    'valid': ds_validate,\n",
    "    'test': ds_test\n",
    "        })\n",
    "\n",
    "del df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.VERBOSE:\n",
    "    print(ds_train)\n",
    "    print(ds_validate)\n",
    "    print(ds_test)\n",
    "    print('----------------------------------')\n",
    "    print(ds_test[0]['input_ids'])\n",
    "    print(len(ds_test[0]['input_ids']))\n",
    "    print(ds_test[0]['attention_mask'])\n",
    "    print(len(ds_test[0]['attention_mask']))\n",
    "    print(ds_test[0]['labels'])\n",
    "    print(len(ds_test[0]['labels']))\n",
    "    print('----------------------------------')\n",
    "    print(t5_tokenizer.decode(ds_test[0]['input_ids']))\n",
    "    print(t5_tokenizer.decode(range(0, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence_examples = [\"PRTEINO\", \"SEQWENCE\"]\n",
    "# sequence_examples = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence))) for sequence in sequence_examples]\n",
    "# ids = t5_tokenizer.batch_encode_plus(sequence_examples, add_special_tokens=True, padding=\"longest\")\n",
    "# input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "# attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
    "# print(input_ids)\n",
    "# print(attention_mask)\n",
    "# with torch.no_grad():\n",
    "#     embedding_repr = t5_base_model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "\n",
    "# emb_0 = embedding_repr.last_hidden_state[0,:7]\n",
    "# print(f\"Shape of per-residue embedding of first sequences: {emb_0.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Apply LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 983,040 || all params: 1,209,124,864 || trainable%: 0.0813017769519625\n"
     ]
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "        task_type=TaskType.FEATURE_EXTRACTION,\n",
    "        inference_mode=False,\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.05,\n",
    "        # target_modules=['q', 'k', 'v', 'o'],\n",
    "        target_modules=['o'],\n",
    "        bias=\"none\",\n",
    "    )\n",
    "t5_lora_model = get_peft_model(t5_base_model, lora_config)\n",
    "# t5_lora_model = prepare_model_for_kbit_training(t5_lora_model) # add quantization\n",
    "# t5_lora_model = t5_base_model\n",
    "t5_lora_model.print_trainable_parameters()\n",
    "# del t5_base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.VERBOSE:\n",
    "    print(t5_lora_model)\n",
    "    print()\n",
    "    print(t5_lora_model.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_tensor_input = torch.tensor([[4, 7, 7, 12, 10, 8]]).to('mps')\n",
    "# t_tensor_mask = torch.tensor([[1, 1, 1, 1, 0, 0]]).to('mps')\n",
    "\n",
    "# t_tensor_input = torch.tensor([[4, 7, 7, 12, 10, 8]]).to('mps')\n",
    "# t_tensor_mask = torch.tensor([[1, 1, 1, 1, 0, 0]]).to('mps')\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     res = t5_lora_model(\n",
    "#         input_ids=t_tensor,\n",
    "#         attention_mask=t_tensor_mask,\n",
    "#         )\n",
    "# print(res)\n",
    "# print(res.last_hidden_state.argmax(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Loop\n",
    "https://huggingface.co/docs/peft/task_guides/token-classification-lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=t5_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_lora_model = inject_linear_layer(\n",
    "    t5_lora_model=t5_lora_model,\n",
    "    num_labels=len(config.label_decoding),\n",
    "    dropout_rate=config.dropout_rate\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5_lora_model.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "# def compute_metrics_custom(eval_preds: EvalPrediction):\n",
    "#     print(*eval_preds)\n",
    "#     logits, labels = eval_preds\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./checkpoints',\n",
    "    learning_rate=config.lr,\n",
    "    per_device_train_batch_size=config.batch_size,\n",
    "    per_device_eval_batch_size=config.batch_size,\n",
    "    num_train_epochs=config.num_epochs,\n",
    "    logging_steps=config.logging_steps,\n",
    "    # save_strategy=\"steps\",\n",
    "    save_steps=config.save_steps,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # eval_steps=config.eval_steps,\n",
    "    # load_best_model_at_end=True,\n",
    "    # save_total_limit=5,\n",
    "    seed=42,\n",
    "    # fp16=True,\n",
    "    # deepspeed=deepspeed_config\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=t5_lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_signalp['train'],\n",
    "    # eval_dataset=ds_validate,\n",
    "    data_collator=data_collator,\n",
    "    # compute_metrics=config.metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ([set(x) for x in ds_validate['labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_validate['labels'][\n",
    "#     [set(x) for x in ds_validate['labels']] != {0}\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "# print(next(t5_lora_model.parameters()).is_cuda)\n",
    "print(t5_lora_model.device)\n",
    "# print(config.label_decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5Config {\n",
      "  \"_name_or_path\": \"Rostlab/prot_t5_xl_uniref50\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 16384,\n",
      "  \"d_kv\": 128,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 32,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"transformers_version\": \"4.35.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(t5_lora_model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d9c041a30d4de4afd673ead77f9435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n",
      "True\n",
      "\n",
      "<class 'peft.peft_model.PeftModelForFeatureExtraction'>\n",
      "PeftModelForFeatureExtraction(\n",
      "  (base_model): LoraModel(\n",
      "    (model): T5EncoderModel(\n",
      "      (shared): Embedding(128, 1024)\n",
      "      (encoder): T5Stack(\n",
      "        (embed_tokens): Embedding(128, 1024)\n",
      "        (block): ModuleList(\n",
      "          (0): T5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): T5LayerSelfAttention(\n",
      "                (SelfAttention): T5Attention(\n",
      "                  (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "                  (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "                  (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "                  (o): Linear(\n",
      "                    in_features=4096, out_features=1024, bias=False\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                  (relative_attention_bias): Embedding(32, 32)\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): T5LayerFF(\n",
      "                (DenseReluDense): T5DenseActDense(\n",
      "                  (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
      "                  (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): ReLU()\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1-23): 23 x T5Block(\n",
      "            (layer): ModuleList(\n",
      "              (0): T5LayerSelfAttention(\n",
      "                (SelfAttention): T5Attention(\n",
      "                  (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "                  (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "                  (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "                  (o): Linear(\n",
      "                    in_features=4096, out_features=1024, bias=False\n",
      "                    (lora_dropout): ModuleDict(\n",
      "                      (default): Dropout(p=0.05, inplace=False)\n",
      "                    )\n",
      "                    (lora_A): ModuleDict(\n",
      "                      (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                    )\n",
      "                    (lora_B): ModuleDict(\n",
      "                      (default): Linear(in_features=8, out_features=1024, bias=False)\n",
      "                    )\n",
      "                    (lora_embedding_A): ParameterDict()\n",
      "                    (lora_embedding_B): ParameterDict()\n",
      "                  )\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (1): T5LayerFF(\n",
      "                (DenseReluDense): T5DenseActDense(\n",
      "                  (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
      "                  (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (act): ReLU()\n",
      "                )\n",
      "                (layer_norm): T5LayerNorm()\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (final_layer_norm): T5LayerNorm()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=1024, out_features=6, bias=True)\n",
      ")\n",
      "Linear(in_features=1024, out_features=6, bias=True)\n",
      "\n",
      "<class 'transformers.modeling_outputs.BaseModelOutputWithPastAndCrossAttentions'>\n",
      "\n",
      "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[ 1.6187e-01, -3.8335e-01,  9.9022e-02,  ...,  1.2837e-01,\n",
      "          -9.9132e-02, -4.4073e-02],\n",
      "         [ 1.1681e-01, -1.0211e-01, -0.0000e+00,  ...,  4.1995e-01,\n",
      "          -0.0000e+00, -9.6149e-02],\n",
      "         [ 1.7909e-02, -1.4590e-01, -0.0000e+00,  ..., -1.1099e-01,\n",
      "          -1.4032e-02,  2.4049e-01],\n",
      "         ...,\n",
      "         [-2.9883e-03, -5.4004e-01, -6.8550e-02,  ..., -1.6163e-02,\n",
      "          -1.6736e-02,  1.0066e-01],\n",
      "         [ 1.4648e-01, -4.0665e-01, -7.6604e-02,  ...,  1.3671e-01,\n",
      "          -0.0000e+00, -2.7428e-01],\n",
      "         [-2.6552e-02, -1.1350e-01, -4.6010e-02,  ..., -8.1452e-02,\n",
      "          -1.2822e-02, -1.4128e-02]],\n",
      "\n",
      "        [[-2.0319e-02, -3.8743e-01,  6.0872e-02,  ...,  1.3160e-01,\n",
      "           1.7457e-01,  1.0217e-01],\n",
      "         [-5.9294e-02, -2.7975e-01, -3.9544e-04,  ...,  0.0000e+00,\n",
      "          -1.6569e-01,  8.7894e-02],\n",
      "         [ 3.9720e-01, -2.1455e-01, -1.3854e-01,  ...,  6.0021e-02,\n",
      "           2.9757e-01,  2.4026e-01],\n",
      "         ...,\n",
      "         [ 1.4774e-02, -2.0052e-02,  1.3265e-01,  ...,  0.0000e+00,\n",
      "           9.3303e-02,  0.0000e+00],\n",
      "         [-1.0353e-01, -3.9150e-01,  0.0000e+00,  ..., -6.9371e-02,\n",
      "          -3.7609e-01,  3.8066e-01],\n",
      "         [-4.4434e-02, -0.0000e+00, -9.6421e-02,  ..., -3.0547e-02,\n",
      "          -5.6932e-02,  3.6475e-02]],\n",
      "\n",
      "        [[-2.9714e-02, -2.0103e-01, -1.2784e-01,  ...,  1.5285e-01,\n",
      "           1.9335e-01,  6.7976e-02],\n",
      "         [-1.2169e-01, -7.3131e-02,  3.9818e-02,  ...,  3.3632e-01,\n",
      "           4.3331e-01, -2.0606e-01],\n",
      "         [-1.4324e-01,  6.8912e-02,  6.8199e-02,  ...,  1.5882e-01,\n",
      "           1.5072e-01, -9.0196e-02],\n",
      "         ...,\n",
      "         [ 7.9928e-03, -2.5379e-01,  1.0340e-02,  ..., -1.7735e-01,\n",
      "          -8.3830e-02, -2.7909e-01],\n",
      "         [-1.2481e-01, -1.1674e-01, -7.7318e-02,  ..., -2.8120e-02,\n",
      "           4.3602e-03, -1.9897e-01],\n",
      "         [-6.4990e-02, -1.2428e-01,  1.4644e-01,  ..., -3.3834e-02,\n",
      "          -8.0303e-02,  3.1222e-02]]], device='mps:0', grad_fn=<MulBackward0>), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)\n",
      "\n",
      "torch.Size([3, 71, 1024])\n",
      "\n",
      "tensor([[[ 1.6187e-01, -3.8335e-01,  9.9022e-02,  ...,  1.2837e-01,\n",
      "          -9.9132e-02, -4.4073e-02],\n",
      "         [ 1.1681e-01, -1.0211e-01, -0.0000e+00,  ...,  4.1995e-01,\n",
      "          -0.0000e+00, -9.6149e-02],\n",
      "         [ 1.7909e-02, -1.4590e-01, -0.0000e+00,  ..., -1.1099e-01,\n",
      "          -1.4032e-02,  2.4049e-01],\n",
      "         ...,\n",
      "         [-2.9883e-03, -5.4004e-01, -6.8550e-02,  ..., -1.6163e-02,\n",
      "          -1.6736e-02,  1.0066e-01],\n",
      "         [ 1.4648e-01, -4.0665e-01, -7.6604e-02,  ...,  1.3671e-01,\n",
      "          -0.0000e+00, -2.7428e-01],\n",
      "         [-2.6552e-02, -1.1350e-01, -4.6010e-02,  ..., -8.1452e-02,\n",
      "          -1.2822e-02, -1.4128e-02]],\n",
      "\n",
      "        [[-2.0319e-02, -3.8743e-01,  6.0872e-02,  ...,  1.3160e-01,\n",
      "           1.7457e-01,  1.0217e-01],\n",
      "         [-5.9294e-02, -2.7975e-01, -3.9544e-04,  ...,  0.0000e+00,\n",
      "          -1.6569e-01,  8.7894e-02],\n",
      "         [ 3.9720e-01, -2.1455e-01, -1.3854e-01,  ...,  6.0021e-02,\n",
      "           2.9757e-01,  2.4026e-01],\n",
      "         ...,\n",
      "         [ 1.4774e-02, -2.0052e-02,  1.3265e-01,  ...,  0.0000e+00,\n",
      "           9.3303e-02,  0.0000e+00],\n",
      "         [-1.0353e-01, -3.9150e-01,  0.0000e+00,  ..., -6.9371e-02,\n",
      "          -3.7609e-01,  3.8066e-01],\n",
      "         [-4.4434e-02, -0.0000e+00, -9.6421e-02,  ..., -3.0547e-02,\n",
      "          -5.6932e-02,  3.6475e-02]],\n",
      "\n",
      "        [[-2.9714e-02, -2.0103e-01, -1.2784e-01,  ...,  1.5285e-01,\n",
      "           1.9335e-01,  6.7976e-02],\n",
      "         [-1.2169e-01, -7.3131e-02,  3.9818e-02,  ...,  3.3632e-01,\n",
      "           4.3331e-01, -2.0606e-01],\n",
      "         [-1.4324e-01,  6.8912e-02,  6.8199e-02,  ...,  1.5882e-01,\n",
      "           1.5072e-01, -9.0196e-02],\n",
      "         ...,\n",
      "         [ 7.9928e-03, -2.5379e-01,  1.0340e-02,  ..., -1.7735e-01,\n",
      "          -8.3830e-02, -2.7909e-01],\n",
      "         [-1.2481e-01, -1.1674e-01, -7.7318e-02,  ..., -2.8120e-02,\n",
      "           4.3602e-03, -1.9897e-01],\n",
      "         [-6.4990e-02, -1.2428e-01,  1.4644e-01,  ..., -3.3834e-02,\n",
      "          -8.0303e-02,  3.1222e-02]]], device='mps:0', grad_fn=<MulBackward0>)\n",
      "\n",
      "torch.Size([3, 71, 1024])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/gits/prottrans-t5-signalpeptide-prediction/.venv/lib/python3.11/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/gits/prottrans-t5-signalpeptide-prediction/.venv/lib/python3.11/site-packages/transformers/trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1860\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1863\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1866\u001b[0m ):\n\u001b[1;32m   1867\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Developer/gits/prottrans-t5-signalpeptide-prediction/.venv/lib/python3.11/site-packages/transformers/trainer.py:2725\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2724\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2725\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2728\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/gits/prottrans-t5-signalpeptide-prediction/.venv/lib/python3.11/site-packages/transformers/trainer.py:2748\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2747\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2748\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2749\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2750\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Developer/gits/prottrans-t5-signalpeptide-prediction/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Developer/gits/prottrans-t5-signalpeptide-prediction/src/model.py:180\u001b[0m, in \u001b[0;36minjected_forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# print(logits.view(-1, self.num_labels))\u001b[39;00m\n\u001b[1;32m    179\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels:\n\u001b[1;32m    181\u001b[0m     loss_fct \u001b[38;5;241m=\u001b[39m CrossEntropyLoss()\n\u001b[1;32m    183\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(logits\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics=trainer.evaluate()\n",
    "# print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_validate['labels'][9].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ds_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = torch.zeros(4148,70)\n",
    "# target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x + [-1] * (70-len(x)) for x in ds_validate['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inlab = torch.tensor([x + [-1] * (70-len(x)) for x in ds_validate['labels']]).to('cpu')\n",
    "# inlab.shape\n",
    "# del inlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inid = torch.tensor(ds_validate['input_ids']).to(device)\n",
    "# inid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = t5_lora_model(input_ids=inid[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for index, _ in enumerate(inid):\n",
    "#     if index % 100 == 0:\n",
    "#         torch.cuda.empty_cache()\n",
    "#     results += t5_lora_model(input_ids=inid[index:index+1]).logits.argmax(dim=-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_labels = [[config.label_decoding[y] for y in x] for x in ds_validate['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(correct_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct = 0\n",
    "# incorrect = 0\n",
    "\n",
    "# for index, item in enumerate(results):\n",
    "#     truth = correct_labels[index]\n",
    "#     prediction = [config.label_decoding[x] for x in item[:len(correct_labels[index])]]\n",
    "    \n",
    "#     if index % 50 == 0:\n",
    "#         print(*truth, sep='')\n",
    "#         print(*prediction, sep='')\n",
    "#         print()\n",
    "    \n",
    "#     for t, p in zip(truth, prediction):\n",
    "#         if t == p:\n",
    "#             correct += 1\n",
    "#         else:\n",
    "#             incorrect += 1\n",
    "    \n",
    "\n",
    "    \n",
    "# print(\"Correct\", correct)\n",
    "# print(\"Incorrect\", incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(correct/(correct+incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(*prediction[0].argmax(dim=-1)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(*[config.label_decoding[x] for x in prediction[0].argmax(dim=-1)[0].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prediction[0].argmax(dim=-1))\n",
    "# print(inlab)\n",
    "# print(inlab == prediction[0].argmax(dim=-1)[:, :70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cust_pred = EvalPrediction(prediction, inlab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(*cust_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_metrics_custom(cust_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log = pd.DataFrame(trainer.state.log_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(result_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "my_plot = sns.lineplot(data=result_log, x='epoch', y='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = my_plot.get_figure()\n",
    "fig.savefig(\"./plots/out.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_lora_model.save_pretrained(ROOT + f'/models/{config.model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reload Model and compare weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = config.label_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_location = '/models/linear_model_v3'\n",
    "t5_lora_model_config = PeftConfig.from_pretrained(ROOT + adapter_location)\n",
    "t5_base_model = PeftModel.from_pretrained(\n",
    "    model=t5_base_model,\n",
    "    model_id=ROOT+adapter_location,\n",
    ")\n",
    "t5_lora_model = inject_linear_layer(t5_base_model, dropout_rate=config.dropout_rate, num_labels=len(label_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
