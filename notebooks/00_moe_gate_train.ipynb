{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/finnlueth/Developer/gits/prottrans-t5-signalpeptide-prediction/.venv/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "import src.config\n",
    "import src.data\n",
    "import src.model_new\n",
    "import src.utils\n",
    "from src.model_new import (\n",
    "    T5EncoderModelForSequenceClassification,\n",
    ")\n",
    "\n",
    "import gc\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import src.utils\n",
    "\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    T5ForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback\n",
    ")\n",
    "\n",
    "import peft\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model:\t Rostlab/prot_t5_xl_uniref50\n",
      "MPS:\t\t True\n",
      "Path:\t\t /Users/finnlueth/Developer/gits/prottrans-t5-signalpeptide-prediction\n",
      "Using device:\t mps\n"
     ]
    }
   ],
   "source": [
    "ROOT = src.utils.get_project_root_path()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "\n",
    "EXPERT = 'ALL'\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Base Model:\\t\", src.config.base_model_name)\n",
    "print(\"MPS:\\t\\t\", torch.backends.mps.is_available())\n",
    "print(\"Path:\\t\\t\", ROOT)\n",
    "print(f\"Using device:\\t {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=src.config.base_model_name,\n",
    "    do_lower_case=False,\n",
    "    use_fast=True,\n",
    "    legacy=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/finnlueth/Developer/gits/prottrans-t5-signalpeptide-prediction/.venv/lib/python3.11/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/Users/finnlueth/Developer/gits/prottrans-t5-signalpeptide-prediction/.venv/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "FASTA_FILENAME = '5_SignalP_5.0_Training_set.fasta'\n",
    "# FASTA_FILENAME = '5_SignalP_5.0_Training_set_testing.fasta'\n",
    "annotations_name = 'Type' # Choose Type or Label\n",
    "\n",
    "df_data = src.data.process(src.data.parse_file(ROOT + '/data/raw/' + FASTA_FILENAME))\n",
    "\n",
    "dataset_signalp = src.model_new.create_datasets(\n",
    "        splits=src.config.splits,\n",
    "        tokenizer=t5_tokenizer,\n",
    "        data=df_data,\n",
    "        annotations_name=annotations_name,\n",
    "        dataset_size=src.config.dataset_size,\n",
    "        encoder=src.config.type_encoding,\n",
    "    )\n",
    "\n",
    "del df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataset_signalp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.Series(dataset_signalp['train']['labels']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5EncoderModelForSequenceClassification were not initialized from the model checkpoint at Rostlab/prot_t5_xl_uniref50 and are newly initialized: ['custom_classifier_in.bias', 'custom_classifier_out.weight', 'custom_classifier_out.bias', 'custom_classifier_in.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,039,560 || all params: 1,214,181,384 || trainable%: 0.49741826712111736\n"
     ]
    }
   ],
   "source": [
    "t5_base_model = T5EncoderModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=src.config.base_model_name,\n",
    "    device_map='auto',\n",
    "    load_in_8bit=False,\n",
    "    custom_num_labels=len(src.config.type_encoding),\n",
    "    custom_dropout_rate=0.1,\n",
    ")\n",
    "\n",
    "tmp_lin_in = nn.Linear(\n",
    "    in_features=t5_base_model.config.hidden_size,\n",
    "    out_features=t5_base_model.config.hidden_size\n",
    ")\n",
    "tmp_lin_out = nn.Linear(\n",
    "    in_features=t5_base_model.config.hidden_size,\n",
    "    out_features=t5_base_model.custom_num_labels\n",
    ")\n",
    "\n",
    "t5_base_model.custom_classifier_in.weight = tmp_lin_in.weight\n",
    "t5_base_model.custom_classifier_in.bias = tmp_lin_in.bias\n",
    "t5_base_model.custom_classifier_out.weight = tmp_lin_out.weight\n",
    "t5_base_model.custom_classifier_out.bias = tmp_lin_out.bias\n",
    "\n",
    "modules_to_save = ['custom_classifier_in', 'custom_classifier_out']\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=['q', 'k', 'v', 'o'],\n",
    "    bias=\"none\",\n",
    "    modules_to_save=modules_to_save,\n",
    ")\n",
    "\n",
    "t5_lora_model = peft.get_peft_model(t5_base_model, lora_config)\n",
    "t5_lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_collator = DataCollatorForTokenClassification(tokenizer=t5_tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./checkpoints',\n",
    "    learning_rate=src.config.lr,\n",
    "    per_device_train_batch_size=src.config.batch_size,\n",
    "    per_device_eval_batch_size=src.config.batch_size,\n",
    "    num_train_epochs=src.config.num_epochs,\n",
    "    logging_steps=src.config.logging_steps,\n",
    "    # save_strategy=\"steps\",\n",
    "    # save_steps=src.config.save_steps,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # eval_steps=src.config.eval_steps,\n",
    "    # gradient_accumulation_steps=accum,\n",
    "    # load_best_model_at_end=True,\n",
    "    # save_total_limit=5,\n",
    "    seed=42,\n",
    "    # fp16=True,\n",
    "    # deepspeed=deepspeed_config,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=['labels'],\n",
    "    # debug=\"underflow_overflow\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=t5_lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_signalp['train'],\n",
    "    eval_dataset=dataset_signalp['valid'],\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=src.model_new.compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(12943) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cedb11d49f54fef8732792144810c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_output.requires_grad True\n",
      "{'loss': 1.38, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'train_runtime': 37.4102, 'train_samples_per_second': 0.241, 'train_steps_per_second': 0.027, 'train_loss': 1.380028247833252, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1, training_loss=1.380028247833252, metrics={'train_runtime': 37.4102, 'train_samples_per_second': 0.241, 'train_steps_per_second': 0.027, 'train_loss': 1.380028247833252, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# torch.mps.empty_cache()\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log = pd.DataFrame(trainer.state.log_history)\n",
    "display(training_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_location = '/models/moe_v1_gate'\n",
    "training_log['eval_confusion_matrix'] = training_log['eval_confusion_matrix'].apply(lambda x: x.tolist() if type(x)==np.ndarray else None)\n",
    "t5_lora_model.save_pretrained(ROOT + adapter_location)\n",
    "training_log.to_csv(ROOT + adapter_location + '/training_log.csv', index=False)\n",
    "training_log.to_parquet(ROOT + adapter_location + '/training_log.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ds_index = 2\n",
    "_ds_type = 'test'\n",
    "\n",
    "_input_ids_test = t5_tokenizer.decode(dataset_signalp[_ds_type][_ds_index]['input_ids'][:-1])\n",
    "_labels_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['labels']]).to(device)\n",
    "_attention_mask_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['attention_mask']]).to(device)\n",
    "\n",
    "_labels_test_decoded = [src.config.type_decoding[x] for x in _labels_test.tolist()]\n",
    "\n",
    "print('Iput IDs:\\t', _input_ids_test)\n",
    "print('Labels:\\t\\t', _labels_test.tolist()[0])\n",
    "print('Labels Decoded:\\t', *_labels_test_decoded)\n",
    "print('Attention Mask:\\t', *_attention_mask_test.tolist()[0])\n",
    "print('----')\n",
    "\n",
    "preds = src.model_new.predict_model(\n",
    "    sequence=_input_ids_test,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    model=t5_lora_model,\n",
    "    labels=_labels_test,\n",
    "    attention_mask=_attention_mask_test,\n",
    "    device=device,\n",
    "    )\n",
    "\n",
    "_result = src.model_new.translate_logits(\n",
    "    logits=preds.logits.unsqueeze(0),\n",
    "    decoding=src.config.type_decoding\n",
    "    )\n",
    "\n",
    "print('logits\\t\\t', preds.logits)\n",
    "print('Result: \\t',* _result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.round(preds.logits.softmax(-1), decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
