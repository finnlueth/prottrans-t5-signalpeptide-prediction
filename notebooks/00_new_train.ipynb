{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback\n",
    ")\n",
    "\n",
    "from src.model_new import (\n",
    "    T5EncoderModelForTokenClassification\n",
    ")\n",
    "\n",
    "import src.config\n",
    "import src.data\n",
    "import src.model_new\n",
    "import src.utils\n",
    "\n",
    "\n",
    "import peft\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    ")\n",
    "\n",
    "\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Base Model:\\t\", src.config.base_model_name)\n",
    "print(\"MPS:\\t\\t\", torch.backends.mps.is_available())\n",
    "ROOT = src.utils.get_project_root_path()\n",
    "print(\"Path:\\t\\t\", ROOT)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "print(f\"Using device:\\t {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Tokenizer and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=src.config.base_model_name,\n",
    "    do_lower_case=False,\n",
    "    use_fast=True,\n",
    "    legacy=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_base_model = T5EncoderModelForTokenClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=src.config.base_model_name,\n",
    "    device_map='auto',\n",
    "    load_in_8bit=False,\n",
    "    custom_num_labels=len(src.config.label_decoding),\n",
    "    custom_dropout_rate=0.1,\n",
    "    use_crf=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_base_model.custom_classifier.weight = nn.Linear(\n",
    "    in_features=t5_base_model.config.hidden_size,\n",
    "    out_features=t5_base_model.custom_num_labels).weight\n",
    "t5_base_model.crf.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Apply LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=['q', 'k', 'v', 'o'],\n",
    "    bias=\"none\",\n",
    "    modules_to_save=['custom_classifier', 'crf'],\n",
    ")\n",
    "\n",
    "t5_lora_model = peft.get_peft_model(t5_base_model, lora_config)\n",
    "t5_lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5_lora_model.base_model.custom_classifier.modules_to_save.default.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x[0] for x in t5_base_model.crf.named_parameters()]\n",
    "# t5_lora_model.crf.transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x for x in t5_lora_model.named_parameters() if 'crf' in x[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Data, Split into Dataset, and Tokenize Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTA_FILENAME = '5_SignalP_5.0_Training_set.fasta'\n",
    "# FASTA_FILENAME = '5_SignalP_5.0_Training_set_testing.fasta'\n",
    "annotations_name = 'Label' # Choose Type or Label\n",
    "\n",
    "df_data = src.data.process(src.data.parse_file(ROOT + '/data/raw/' + FASTA_FILENAME))\n",
    "\n",
    "dataset_signalp = src.model_new.create_datasets(\n",
    "    splits=src.config.splits,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    data=df_data,\n",
    "    annotations_name=annotations_name,\n",
    "    dataset_size=src.config.dataset_size,\n",
    "    # dataset_size=3,\n",
    "    encoder=src.config.select_encodings[annotations_name],\n",
    "    )\n",
    "\n",
    "del df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_signalp)\n",
    "\n",
    "ds_index = 0\n",
    "print(dataset_signalp['valid'][ds_index]['input_ids'])\n",
    "print(dataset_signalp['valid'][ds_index]['labels'])\n",
    "print(dataset_signalp['valid'][ds_index]['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torchcrf import CRF\n",
    "# num_tags = 5\n",
    "# model = CRF(num_tags=num_tags, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 2\n",
    "# seq_length = 4\n",
    "# emissions = torch.randn(batch_size, seq_length, num_tags)\n",
    "# tags = torch.tensor([\n",
    "#     [1, 2, 3, 3],\n",
    "#     [2, 2, 2, 3]\n",
    "#     ], dtype=torch.long)  # (seq_length, batch_size)\n",
    "\n",
    "# display(emissions, emissions.shape)\n",
    "# display(tags, tags.shape)\n",
    "# display(model(emissions, tags))\n",
    "# display(torch.Tensor(model.decode(emissions)).shape)\n",
    "# display(model.decode(emissions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Loop\n",
    "https://huggingface.co/docs/peft/task_guides/token-classification-lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=t5_tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./checkpoints',\n",
    "    learning_rate=src.config.lr,\n",
    "    per_device_train_batch_size=src.config.batch_size,\n",
    "    per_device_eval_batch_size=src.config.batch_size,\n",
    "    num_train_epochs=src.config.num_epochs,\n",
    "    logging_steps=src.config.logging_steps,\n",
    "    # save_strategy=\"steps\",\n",
    "    # save_steps=src.config.save_steps,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # eval_steps=src.config.eval_steps,\n",
    "    # gradient_accumulation_steps=accum,\n",
    "    # load_best_model_at_end=True,\n",
    "    # save_total_limit=5,\n",
    "    seed=42,\n",
    "    # fp16=True,\n",
    "    # deepspeed=deepspeed_config,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=['labels'],\n",
    "    # debug=\"underflow_overflow\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=t5_lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_signalp['train'],\n",
    "    eval_dataset=dataset_signalp['valid'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=src.model_new.compute_metrics,\n",
    ")\n",
    "\n",
    "# class EvaluateFirstStepCallback(TrainerCallback):\n",
    "#     def on_step_begin(self, args, state, control, **kwargs):\n",
    "#         if state.global_step == 0:\n",
    "#             control.should_evaluate = True\n",
    "# trainer.add_callback(EvaluateFirstStepCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_lora_model.crf.modules_to_save.default.decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log = pd.DataFrame(trainer.state.log_history)\n",
    "display(training_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_location = '/models/testing_1'\n",
    "training_log['eval_confusion_matrix'] = training_log['eval_confusion_matrix'].apply(lambda x: x.tolist() if type(x)==np.ndarray else None)\n",
    "t5_lora_model.save_pretrained(ROOT + adapter_location)\n",
    "training_log.to_csv(ROOT + adapter_location + '/training_log.csv', index=False)\n",
    "training_log.to_parquet(ROOT + adapter_location + '/training_log.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ds_index = 2\n",
    "_ds_type = 'test'\n",
    "\n",
    "_input_ids_test = t5_tokenizer.decode(dataset_signalp[_ds_type][_ds_index]['input_ids'])\n",
    "_labels_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['labels'] + [-100]]).to(device)\n",
    "_attention_mask_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['attention_mask']]).to(device)\n",
    "\n",
    "_labels_test_decoded = [src.config.label_decoding[x] for x in _labels_test.tolist()[0][:-1]]\n",
    "\n",
    "print('Iput IDs:\\t', _input_ids_test)\n",
    "print('Labels:\\t\\t', *_labels_test.tolist()[0])\n",
    "print('Labels Decoded:\\t', *_labels_test_decoded)\n",
    "print('Attention Mask:\\t', *_attention_mask_test.tolist()[0])\n",
    "print('----')\n",
    "\n",
    "viterbi_decoding=False\n",
    "\n",
    "preds = src.model_new.predict_model(\n",
    "    sequence=_input_ids_test,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    model=t5_lora_model,\n",
    "    labels=_labels_test,\n",
    "    attention_mask=_attention_mask_test,\n",
    "    device=device,\n",
    "    viterbi_decoding=viterbi_decoding,\n",
    "    )\n",
    "\n",
    "_result = src.model_new.translate_logits(\n",
    "    logits=preds.logits,\n",
    "    viterbi_decoding=viterbi_decoding,\n",
    "    )\n",
    "\n",
    "print('Result: \\t',* _result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_printoptions(threshold=10_000)\n",
    "# t5_lora_model.custom_classifier.modules_to_save.default.weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
