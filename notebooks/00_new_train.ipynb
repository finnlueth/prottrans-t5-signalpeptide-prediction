{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import copy\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback\n",
    ")\n",
    "\n",
    "from src.model_new import (\n",
    "    T5EncoderModelForTokenClassification\n",
    ")\n",
    "\n",
    "import src.config\n",
    "import src.data\n",
    "import src.model_new\n",
    "import src.utils\n",
    "\n",
    "\n",
    "import peft\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    ")\n",
    "\n",
    "\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model:\t Rostlab/prot_t5_xl_uniref50\n",
      "MPS:\t\t False\n",
      "Path:\t\t /home/ec2-user/developer/prottrans-t5-signalpeptide-prediction\n",
      "Using device:\t cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"Base Model:\\t\", src.config.base_model_name)\n",
    "print(\"MPS:\\t\\t\", torch.backends.mps.is_available())\n",
    "ROOT = src.utils.get_project_root_path()\n",
    "print(\"Path:\\t\\t\", ROOT)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "print(f\"Using device:\\t {device}\")\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\"\n",
    "use_crf = False\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Tokenizer and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=src.config.base_model_name,\n",
    "    do_lower_case=False,\n",
    "    use_fast=True,\n",
    "    legacy=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5EncoderModelForTokenClassification were not initialized from the model checkpoint at Rostlab/prot_t5_xl_uniref50 and are newly initialized: ['custom_classifier.bias', 'custom_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "t5_base_model = T5EncoderModelForTokenClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=src.config.base_model_name,\n",
    "    device_map='auto',\n",
    "    load_in_8bit=False,\n",
    "    custom_num_labels=len(src.config.label_decoding),\n",
    "    custom_dropout_rate=0.1,\n",
    "    use_crf=use_crf\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_base_model.custom_classifier.weight = nn.Linear(\n",
    "    in_features=t5_base_model.config.hidden_size,\n",
    "    out_features=t5_base_model.custom_num_labels\n",
    ").weight\n",
    "if use_crf:\n",
    "    t5_base_model.crf.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Apply LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,944,460 || all params: 1,212,086,284 || trainable%: 0.32542732741623864\n"
     ]
    }
   ],
   "source": [
    "if use_crf:\n",
    "    modules_to_save = ['custom_classifier', 'crf']\n",
    "else:\n",
    "    modules_to_save = ['custom_classifier']\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=['q', 'k', 'v', 'o'],\n",
    "    bias=\"none\",\n",
    "    # modules_to_save=modules_to_save,\n",
    "    modules_to_save=['custom_classifier'],\n",
    ")\n",
    "\n",
    "t5_lora_model = peft.get_peft_model(t5_base_model, lora_config)\n",
    "t5_lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0312, grad_fn=<MinBackward1>),\n",
       " tensor(0.0312, grad_fn=<MaxBackward1>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_lora_model.base_model.custom_classifier.modules_to_save.default.weight.min(), t5_lora_model.base_model.custom_classifier.modules_to_save.default.weight.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x[0] for x in t5_base_model.crf.named_parameters()]\n",
    "# t5_lora_model.crf.transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x for x in t5_lora_model.named_parameters() if 'crf' in x[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Data, Split into Dataset, and Tokenize Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTA_FILENAME = '5_SignalP_5.0_Training_set.fasta'\n",
    "# FASTA_FILENAME = '5_SignalP_5.0_Training_set_testing.fasta'\n",
    "annotations_name = 'Label' # Choose Type or Label\n",
    "\n",
    "df_data = src.data.process(src.data.parse_file(ROOT + '/data/raw/' + FASTA_FILENAME))\n",
    "\n",
    "dataset_signalp = src.model_new.create_datasets(\n",
    "    splits=src.config.splits,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    data=df_data,\n",
    "    annotations_name=annotations_name,\n",
    "    # dataset_size=src.config.dataset_size,\n",
    "    dataset_size=3,\n",
    "    encoder=src.config.select_encodings[annotations_name],\n",
    "    )\n",
    "\n",
    "del df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 [19, 14, 13, 13, 7, 11, 16, 7, 7, 13, 3, 3, 6, 3, 3, 3, 3, 13, 3, 19, 10, 7, 3, 3, 3, 3, 10, 4, 11, 10, 6, 4, 22, 9, 15, 10, 3, 6, 4, 3, 10, 15, 3, 7, 13, 15, 20, 9, 8, 20, 15, 20, 18, 9, 9, 20, 4, 9, 8, 19, 14, 8, 8, 7, 7, 3, 7, 6, 7, 10, 1]\n",
      "70 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "71 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "display(dataset_signalp)\n",
    "\n",
    "ds_index = 3\n",
    "print(len(dataset_signalp['train'][ds_index]['input_ids']), dataset_signalp['train'][ds_index]['input_ids'])\n",
    "print(len(dataset_signalp['train'][ds_index]['labels']), dataset_signalp['train'][ds_index]['labels'])\n",
    "print(len(dataset_signalp['train'][ds_index]['attention_mask']), dataset_signalp['train'][ds_index]['attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torchcrf import CRF\n",
    "# num_tags = 5\n",
    "# model = CRF(num_tags=num_tags, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 2\n",
    "# seq_length = 4\n",
    "# emissions = torch.randn(batch_size, seq_length, num_tags)\n",
    "# tags = torch.tensor([\n",
    "#     [1, 2, 3, 3],\n",
    "#     [2, 2, 2, 3]\n",
    "#     ], dtype=torch.long)  # (seq_length, batch_size)\n",
    "\n",
    "# display(emissions, emissions.shape)\n",
    "# display(tags, tags.shape)\n",
    "# display(model(emissions, tags))\n",
    "# display(torch.Tensor(model.decode(emissions)).shape)\n",
    "# display(model.decode(emissions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training Loop\n",
    "https://huggingface.co/docs/peft/task_guides/token-classification-lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=t5_tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./checkpoints',\n",
    "    learning_rate=src.config.lr,\n",
    "    per_device_train_batch_size=src.config.batch_size,\n",
    "    per_device_eval_batch_size=src.config.batch_size,\n",
    "    num_train_epochs=src.config.num_epochs,\n",
    "    logging_steps=src.config.logging_steps,\n",
    "    # save_strategy=\"steps\",\n",
    "    # save_steps=src.config.save_steps,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    # eval_steps=src.config.eval_steps,\n",
    "    # gradient_accumulation_steps=accum,\n",
    "    # load_best_model_at_end=True,\n",
    "    # save_total_limit=5,\n",
    "    seed=SEED,\n",
    "    # fp16=True,\n",
    "    # deepspeed=deepspeed_config,\n",
    "    remove_unused_columns=False,\n",
    "    label_names=['labels'],\n",
    "    # debug=\"underflow_overflow\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=t5_lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_signalp['train'],\n",
    "    eval_dataset=dataset_signalp['valid'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=src.model_new.compute_metrics,\n",
    ")\n",
    "\n",
    "# class EvaluateFirstStepCallback(TrainerCallback):\n",
    "#     def on_step_begin(self, args, state, control, **kwargs):\n",
    "#         if state.global_step == 0:\n",
    "#             control.should_evaluate = True\n",
    "# trainer.add_callback(EvaluateFirstStepCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0312, device='cuda:0', grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_lora_model.custom_classifier.original_module.weight.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.4237e+27, device='cuda:0', grad_fn=<MinBackward1>) tensor(0.4764, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "tensor(False, device='cuda:0')\n",
      "logits tensor([[-4.8972e-02, -1.8654e-02,  5.1627e-02, -3.4237e+27,  2.9514e-01,\n",
      "          5.7991e-02],\n",
      "        [-7.1986e-02, -1.7042e-02, -6.7814e-02, -3.4237e+27,  2.5285e-01,\n",
      "         -2.4287e-02],\n",
      "        [ 6.9416e-02, -1.9611e-02,  1.1845e-01, -3.4237e+27,  4.4818e-02,\n",
      "          1.4938e-01],\n",
      "        ...,\n",
      "        [ 1.7503e-01, -2.8016e-01, -2.9745e-02, -3.4237e+27,  1.6332e-01,\n",
      "          2.2564e-02],\n",
      "        [ 9.0682e-02, -3.5049e-02, -6.4780e-02, -3.4237e+27,  7.8264e-02,\n",
      "          2.6416e-03],\n",
      "        [-2.7950e-02,  3.7203e-02,  5.7097e-02, -3.4237e+27, -7.7143e-02,\n",
      "         -5.1237e-02]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "labels tensor([   4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3, -100,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0, -100,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3, -100,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0, -100,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3, -100,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
      "           3,    3,    3,    3,    3, -100,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0, -100,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0, -100,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0, -100], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>755394981475145381895471104.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1, training_loss=7.553949814751454e+26, metrics={'train_runtime': 0.8156, 'train_samples_per_second': 11.034, 'train_steps_per_second': 1.226, 'total_flos': 4646632356792.0, 'train_loss': 7.553949814751454e+26, 'epoch': 1.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.2319, device='cuda:0') tensor(1.2816, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.2217, device='cuda:0') tensor(1.3702, device='cuda:0')\n",
      "tensor(-1.2800, device='cuda:0') tensor(1.4304, device='cuda:0')\n",
      "tensor(-1.3456, device='cuda:0') tensor(1.3881, device='cuda:0')\n",
      "tensor(-1.1950, device='cuda:0') tensor(1.1463, device='cuda:0')\n",
      "tensor(-1.3821, device='cuda:0') tensor(1.3203, device='cuda:0')\n",
      "tensor(-1.3316, device='cuda:0') tensor(1.2572, device='cuda:0')\n",
      "tensor(-1.3085, device='cuda:0') tensor(1.2676, device='cuda:0')\n",
      "tensor(-1.3280, device='cuda:0') tensor(1.2849, device='cuda:0')\n",
      "tensor(-1.3682, device='cuda:0') tensor(1.2365, device='cuda:0')\n",
      "tensor(-1.4654, device='cuda:0') tensor(1.2441, device='cuda:0')\n",
      "tensor(-1.1798, device='cuda:0') tensor(1.2467, device='cuda:0')\n",
      "tensor(-1.1554, device='cuda:0') tensor(1.2987, device='cuda:0')\n",
      "tensor(-1.4104, device='cuda:0') tensor(1.5904, device='cuda:0')\n",
      "tensor(-1.2398, device='cuda:0') tensor(1.2105, device='cuda:0')\n",
      "tensor(-1.4310, device='cuda:0') tensor(1.4350, device='cuda:0')\n",
      "tensor(-1.2382, device='cuda:0') tensor(1.3113, device='cuda:0')\n",
      "tensor(-1.2532, device='cuda:0') tensor(1.1559, device='cuda:0')\n",
      "tensor(-1.2664, device='cuda:0') tensor(1.1539, device='cuda:0')\n",
      "{'eval_loss': 1.5330615970406334e+19, 'eval_accuracy_metric': 0.022331845238095237, 'eval_precision_metric': 0.022331845238095237, 'eval_recall_metric': 0.022331845238095237, 'eval_f1_metric': 0.022331845238095237, 'eval_matthews_correlation': 0.0, 'eval_confusion_matrix': array([[    0,     0,     0,     0,     0,     0],\n",
      "       [    0,     0,     0,     0,     0,     0],\n",
      "       [15665,   368,   467,  3356,   907,   154],\n",
      "       [    0,     0,     0,     0,     0,     0],\n",
      "       [    0,     0,     0,     0,     0,     0],\n",
      "       [    0,     0,     0,     0,     0,     0]]), 'eval_runtime': 18.2907, 'eval_samples_per_second': 16.402, 'eval_steps_per_second': 1.039, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "metrics=trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5_lora_model.crf.modules_to_save.default.decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_metric</th>\n",
       "      <th>eval_precision_metric</th>\n",
       "      <th>eval_recall_metric</th>\n",
       "      <th>eval_f1_metric</th>\n",
       "      <th>eval_matthews_correlation</th>\n",
       "      <th>eval_confusion_matrix</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.445970e+19</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.538356e+19</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.07</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.538356e+19</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.09</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.540914e+19</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.11</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.486564e+19</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.12</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.555153e+19</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.14</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.569241e+19</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.16</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.542556e+19</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.18</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.508961e+19</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.19</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.507561e+19</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.21</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.557953e+19</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.23</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.568711e+19</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.25</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.555154e+19</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.26</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.535557e+19</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.28</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.515652e+19</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.30</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.32</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.33</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.569903e+19</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.35</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.470661e+19</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.37</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.39</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.545058e+19</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.40</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.479565e+19</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.42</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.537013e+19</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.44</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.46</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.538356e+19</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.47</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.494722e+19</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.49</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.487623e+19</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.51</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.53</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.54</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.487964e+19</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.56</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.538356e+19</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.58</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.436172e+19</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.60</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.490763e+19</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.61</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.438258e+19</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.63</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.508961e+19</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.65</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.517359e+19</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.67</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.538356e+19</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.68</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.532757e+19</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.70</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.535495e+19</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.72</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.540650e+19</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.74</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.75</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.77</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.451593e+19</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.79</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.81</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.473966e+19</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.82</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.479565e+19</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.84</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.86</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.486564e+19</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.88</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.487964e+19</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.89</td>\n",
       "      <td>51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.568811e+19</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.91</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.567752e+19</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.93</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.538356e+19</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.95</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1.535764e+19</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.96</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1.539316e+19</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.98</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.567751e+19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>57</td>\n",
       "      <td>85.4625</td>\n",
       "      <td>10.531</td>\n",
       "      <td>0.667</td>\n",
       "      <td>4.646632e+14</td>\n",
       "      <td>1.529212e+19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.533062e+19</td>\n",
       "      <td>0.022332</td>\n",
       "      <td>0.022332</td>\n",
       "      <td>0.022332</td>\n",
       "      <td>0.022332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [1566...</td>\n",
       "      <td>18.2907</td>\n",
       "      <td>16.402</td>\n",
       "      <td>1.039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss  learning_rate  epoch  step  train_runtime  \\\n",
       "0   1.567752e+19       0.000098   0.02     1            NaN   \n",
       "1   1.567752e+19       0.000096   0.04     2            NaN   \n",
       "2   1.445970e+19       0.000095   0.05     3            NaN   \n",
       "3   1.538356e+19       0.000093   0.07     4            NaN   \n",
       "4   1.538356e+19       0.000091   0.09     5            NaN   \n",
       "5   1.540914e+19       0.000089   0.11     6            NaN   \n",
       "6   1.486564e+19       0.000088   0.12     7            NaN   \n",
       "7   1.555153e+19       0.000086   0.14     8            NaN   \n",
       "8   1.569241e+19       0.000084   0.16     9            NaN   \n",
       "9   1.542556e+19       0.000082   0.18    10            NaN   \n",
       "10  1.508961e+19       0.000081   0.19    11            NaN   \n",
       "11  1.507561e+19       0.000079   0.21    12            NaN   \n",
       "12  1.557953e+19       0.000077   0.23    13            NaN   \n",
       "13  1.568711e+19       0.000075   0.25    14            NaN   \n",
       "14  1.555154e+19       0.000074   0.26    15            NaN   \n",
       "15  1.535557e+19       0.000072   0.28    16            NaN   \n",
       "16  1.515652e+19       0.000070   0.30    17            NaN   \n",
       "17  1.567752e+19       0.000068   0.32    18            NaN   \n",
       "18  1.567752e+19       0.000067   0.33    19            NaN   \n",
       "19  1.569903e+19       0.000065   0.35    20            NaN   \n",
       "20  1.470661e+19       0.000063   0.37    21            NaN   \n",
       "21  1.567752e+19       0.000061   0.39    22            NaN   \n",
       "22  1.545058e+19       0.000060   0.40    23            NaN   \n",
       "23  1.479565e+19       0.000058   0.42    24            NaN   \n",
       "24  1.537013e+19       0.000056   0.44    25            NaN   \n",
       "25  1.567752e+19       0.000054   0.46    26            NaN   \n",
       "26  1.538356e+19       0.000053   0.47    27            NaN   \n",
       "27  1.494722e+19       0.000051   0.49    28            NaN   \n",
       "28  1.487623e+19       0.000049   0.51    29            NaN   \n",
       "29  1.567752e+19       0.000047   0.53    30            NaN   \n",
       "30  1.567752e+19       0.000046   0.54    31            NaN   \n",
       "31  1.487964e+19       0.000044   0.56    32            NaN   \n",
       "32  1.538356e+19       0.000042   0.58    33            NaN   \n",
       "33  1.436172e+19       0.000040   0.60    34            NaN   \n",
       "34  1.490763e+19       0.000039   0.61    35            NaN   \n",
       "35  1.438258e+19       0.000037   0.63    36            NaN   \n",
       "36  1.508961e+19       0.000035   0.65    37            NaN   \n",
       "37  1.517359e+19       0.000033   0.67    38            NaN   \n",
       "38  1.538356e+19       0.000032   0.68    39            NaN   \n",
       "39  1.532757e+19       0.000030   0.70    40            NaN   \n",
       "40  1.535495e+19       0.000028   0.72    41            NaN   \n",
       "41  1.540650e+19       0.000026   0.74    42            NaN   \n",
       "42  1.567752e+19       0.000025   0.75    43            NaN   \n",
       "43  1.567752e+19       0.000023   0.77    44            NaN   \n",
       "44  1.451593e+19       0.000021   0.79    45            NaN   \n",
       "45  1.567752e+19       0.000019   0.81    46            NaN   \n",
       "46  1.473966e+19       0.000018   0.82    47            NaN   \n",
       "47  1.479565e+19       0.000016   0.84    48            NaN   \n",
       "48  1.567752e+19       0.000014   0.86    49            NaN   \n",
       "49  1.486564e+19       0.000012   0.88    50            NaN   \n",
       "50  1.487964e+19       0.000011   0.89    51            NaN   \n",
       "51  1.568811e+19       0.000009   0.91    52            NaN   \n",
       "52  1.567752e+19       0.000007   0.93    53            NaN   \n",
       "53  1.538356e+19       0.000005   0.95    54            NaN   \n",
       "54  1.535764e+19       0.000004   0.96    55            NaN   \n",
       "55  1.539316e+19       0.000002   0.98    56            NaN   \n",
       "56  1.567751e+19       0.000000   1.00    57            NaN   \n",
       "57           NaN            NaN   1.00    57        85.4625   \n",
       "58           NaN            NaN   1.00    57            NaN   \n",
       "\n",
       "    train_samples_per_second  train_steps_per_second    total_flos  \\\n",
       "0                        NaN                     NaN           NaN   \n",
       "1                        NaN                     NaN           NaN   \n",
       "2                        NaN                     NaN           NaN   \n",
       "3                        NaN                     NaN           NaN   \n",
       "4                        NaN                     NaN           NaN   \n",
       "5                        NaN                     NaN           NaN   \n",
       "6                        NaN                     NaN           NaN   \n",
       "7                        NaN                     NaN           NaN   \n",
       "8                        NaN                     NaN           NaN   \n",
       "9                        NaN                     NaN           NaN   \n",
       "10                       NaN                     NaN           NaN   \n",
       "11                       NaN                     NaN           NaN   \n",
       "12                       NaN                     NaN           NaN   \n",
       "13                       NaN                     NaN           NaN   \n",
       "14                       NaN                     NaN           NaN   \n",
       "15                       NaN                     NaN           NaN   \n",
       "16                       NaN                     NaN           NaN   \n",
       "17                       NaN                     NaN           NaN   \n",
       "18                       NaN                     NaN           NaN   \n",
       "19                       NaN                     NaN           NaN   \n",
       "20                       NaN                     NaN           NaN   \n",
       "21                       NaN                     NaN           NaN   \n",
       "22                       NaN                     NaN           NaN   \n",
       "23                       NaN                     NaN           NaN   \n",
       "24                       NaN                     NaN           NaN   \n",
       "25                       NaN                     NaN           NaN   \n",
       "26                       NaN                     NaN           NaN   \n",
       "27                       NaN                     NaN           NaN   \n",
       "28                       NaN                     NaN           NaN   \n",
       "29                       NaN                     NaN           NaN   \n",
       "30                       NaN                     NaN           NaN   \n",
       "31                       NaN                     NaN           NaN   \n",
       "32                       NaN                     NaN           NaN   \n",
       "33                       NaN                     NaN           NaN   \n",
       "34                       NaN                     NaN           NaN   \n",
       "35                       NaN                     NaN           NaN   \n",
       "36                       NaN                     NaN           NaN   \n",
       "37                       NaN                     NaN           NaN   \n",
       "38                       NaN                     NaN           NaN   \n",
       "39                       NaN                     NaN           NaN   \n",
       "40                       NaN                     NaN           NaN   \n",
       "41                       NaN                     NaN           NaN   \n",
       "42                       NaN                     NaN           NaN   \n",
       "43                       NaN                     NaN           NaN   \n",
       "44                       NaN                     NaN           NaN   \n",
       "45                       NaN                     NaN           NaN   \n",
       "46                       NaN                     NaN           NaN   \n",
       "47                       NaN                     NaN           NaN   \n",
       "48                       NaN                     NaN           NaN   \n",
       "49                       NaN                     NaN           NaN   \n",
       "50                       NaN                     NaN           NaN   \n",
       "51                       NaN                     NaN           NaN   \n",
       "52                       NaN                     NaN           NaN   \n",
       "53                       NaN                     NaN           NaN   \n",
       "54                       NaN                     NaN           NaN   \n",
       "55                       NaN                     NaN           NaN   \n",
       "56                       NaN                     NaN           NaN   \n",
       "57                    10.531                   0.667  4.646632e+14   \n",
       "58                       NaN                     NaN           NaN   \n",
       "\n",
       "      train_loss     eval_loss  eval_accuracy_metric  eval_precision_metric  \\\n",
       "0            NaN           NaN                   NaN                    NaN   \n",
       "1            NaN           NaN                   NaN                    NaN   \n",
       "2            NaN           NaN                   NaN                    NaN   \n",
       "3            NaN           NaN                   NaN                    NaN   \n",
       "4            NaN           NaN                   NaN                    NaN   \n",
       "5            NaN           NaN                   NaN                    NaN   \n",
       "6            NaN           NaN                   NaN                    NaN   \n",
       "7            NaN           NaN                   NaN                    NaN   \n",
       "8            NaN           NaN                   NaN                    NaN   \n",
       "9            NaN           NaN                   NaN                    NaN   \n",
       "10           NaN           NaN                   NaN                    NaN   \n",
       "11           NaN           NaN                   NaN                    NaN   \n",
       "12           NaN           NaN                   NaN                    NaN   \n",
       "13           NaN           NaN                   NaN                    NaN   \n",
       "14           NaN           NaN                   NaN                    NaN   \n",
       "15           NaN           NaN                   NaN                    NaN   \n",
       "16           NaN           NaN                   NaN                    NaN   \n",
       "17           NaN           NaN                   NaN                    NaN   \n",
       "18           NaN           NaN                   NaN                    NaN   \n",
       "19           NaN           NaN                   NaN                    NaN   \n",
       "20           NaN           NaN                   NaN                    NaN   \n",
       "21           NaN           NaN                   NaN                    NaN   \n",
       "22           NaN           NaN                   NaN                    NaN   \n",
       "23           NaN           NaN                   NaN                    NaN   \n",
       "24           NaN           NaN                   NaN                    NaN   \n",
       "25           NaN           NaN                   NaN                    NaN   \n",
       "26           NaN           NaN                   NaN                    NaN   \n",
       "27           NaN           NaN                   NaN                    NaN   \n",
       "28           NaN           NaN                   NaN                    NaN   \n",
       "29           NaN           NaN                   NaN                    NaN   \n",
       "30           NaN           NaN                   NaN                    NaN   \n",
       "31           NaN           NaN                   NaN                    NaN   \n",
       "32           NaN           NaN                   NaN                    NaN   \n",
       "33           NaN           NaN                   NaN                    NaN   \n",
       "34           NaN           NaN                   NaN                    NaN   \n",
       "35           NaN           NaN                   NaN                    NaN   \n",
       "36           NaN           NaN                   NaN                    NaN   \n",
       "37           NaN           NaN                   NaN                    NaN   \n",
       "38           NaN           NaN                   NaN                    NaN   \n",
       "39           NaN           NaN                   NaN                    NaN   \n",
       "40           NaN           NaN                   NaN                    NaN   \n",
       "41           NaN           NaN                   NaN                    NaN   \n",
       "42           NaN           NaN                   NaN                    NaN   \n",
       "43           NaN           NaN                   NaN                    NaN   \n",
       "44           NaN           NaN                   NaN                    NaN   \n",
       "45           NaN           NaN                   NaN                    NaN   \n",
       "46           NaN           NaN                   NaN                    NaN   \n",
       "47           NaN           NaN                   NaN                    NaN   \n",
       "48           NaN           NaN                   NaN                    NaN   \n",
       "49           NaN           NaN                   NaN                    NaN   \n",
       "50           NaN           NaN                   NaN                    NaN   \n",
       "51           NaN           NaN                   NaN                    NaN   \n",
       "52           NaN           NaN                   NaN                    NaN   \n",
       "53           NaN           NaN                   NaN                    NaN   \n",
       "54           NaN           NaN                   NaN                    NaN   \n",
       "55           NaN           NaN                   NaN                    NaN   \n",
       "56           NaN           NaN                   NaN                    NaN   \n",
       "57  1.529212e+19           NaN                   NaN                    NaN   \n",
       "58           NaN  1.533062e+19              0.022332               0.022332   \n",
       "\n",
       "    eval_recall_metric  eval_f1_metric  eval_matthews_correlation  \\\n",
       "0                  NaN             NaN                        NaN   \n",
       "1                  NaN             NaN                        NaN   \n",
       "2                  NaN             NaN                        NaN   \n",
       "3                  NaN             NaN                        NaN   \n",
       "4                  NaN             NaN                        NaN   \n",
       "5                  NaN             NaN                        NaN   \n",
       "6                  NaN             NaN                        NaN   \n",
       "7                  NaN             NaN                        NaN   \n",
       "8                  NaN             NaN                        NaN   \n",
       "9                  NaN             NaN                        NaN   \n",
       "10                 NaN             NaN                        NaN   \n",
       "11                 NaN             NaN                        NaN   \n",
       "12                 NaN             NaN                        NaN   \n",
       "13                 NaN             NaN                        NaN   \n",
       "14                 NaN             NaN                        NaN   \n",
       "15                 NaN             NaN                        NaN   \n",
       "16                 NaN             NaN                        NaN   \n",
       "17                 NaN             NaN                        NaN   \n",
       "18                 NaN             NaN                        NaN   \n",
       "19                 NaN             NaN                        NaN   \n",
       "20                 NaN             NaN                        NaN   \n",
       "21                 NaN             NaN                        NaN   \n",
       "22                 NaN             NaN                        NaN   \n",
       "23                 NaN             NaN                        NaN   \n",
       "24                 NaN             NaN                        NaN   \n",
       "25                 NaN             NaN                        NaN   \n",
       "26                 NaN             NaN                        NaN   \n",
       "27                 NaN             NaN                        NaN   \n",
       "28                 NaN             NaN                        NaN   \n",
       "29                 NaN             NaN                        NaN   \n",
       "30                 NaN             NaN                        NaN   \n",
       "31                 NaN             NaN                        NaN   \n",
       "32                 NaN             NaN                        NaN   \n",
       "33                 NaN             NaN                        NaN   \n",
       "34                 NaN             NaN                        NaN   \n",
       "35                 NaN             NaN                        NaN   \n",
       "36                 NaN             NaN                        NaN   \n",
       "37                 NaN             NaN                        NaN   \n",
       "38                 NaN             NaN                        NaN   \n",
       "39                 NaN             NaN                        NaN   \n",
       "40                 NaN             NaN                        NaN   \n",
       "41                 NaN             NaN                        NaN   \n",
       "42                 NaN             NaN                        NaN   \n",
       "43                 NaN             NaN                        NaN   \n",
       "44                 NaN             NaN                        NaN   \n",
       "45                 NaN             NaN                        NaN   \n",
       "46                 NaN             NaN                        NaN   \n",
       "47                 NaN             NaN                        NaN   \n",
       "48                 NaN             NaN                        NaN   \n",
       "49                 NaN             NaN                        NaN   \n",
       "50                 NaN             NaN                        NaN   \n",
       "51                 NaN             NaN                        NaN   \n",
       "52                 NaN             NaN                        NaN   \n",
       "53                 NaN             NaN                        NaN   \n",
       "54                 NaN             NaN                        NaN   \n",
       "55                 NaN             NaN                        NaN   \n",
       "56                 NaN             NaN                        NaN   \n",
       "57                 NaN             NaN                        NaN   \n",
       "58            0.022332        0.022332                        0.0   \n",
       "\n",
       "                                eval_confusion_matrix  eval_runtime  \\\n",
       "0                                                 NaN           NaN   \n",
       "1                                                 NaN           NaN   \n",
       "2                                                 NaN           NaN   \n",
       "3                                                 NaN           NaN   \n",
       "4                                                 NaN           NaN   \n",
       "5                                                 NaN           NaN   \n",
       "6                                                 NaN           NaN   \n",
       "7                                                 NaN           NaN   \n",
       "8                                                 NaN           NaN   \n",
       "9                                                 NaN           NaN   \n",
       "10                                                NaN           NaN   \n",
       "11                                                NaN           NaN   \n",
       "12                                                NaN           NaN   \n",
       "13                                                NaN           NaN   \n",
       "14                                                NaN           NaN   \n",
       "15                                                NaN           NaN   \n",
       "16                                                NaN           NaN   \n",
       "17                                                NaN           NaN   \n",
       "18                                                NaN           NaN   \n",
       "19                                                NaN           NaN   \n",
       "20                                                NaN           NaN   \n",
       "21                                                NaN           NaN   \n",
       "22                                                NaN           NaN   \n",
       "23                                                NaN           NaN   \n",
       "24                                                NaN           NaN   \n",
       "25                                                NaN           NaN   \n",
       "26                                                NaN           NaN   \n",
       "27                                                NaN           NaN   \n",
       "28                                                NaN           NaN   \n",
       "29                                                NaN           NaN   \n",
       "30                                                NaN           NaN   \n",
       "31                                                NaN           NaN   \n",
       "32                                                NaN           NaN   \n",
       "33                                                NaN           NaN   \n",
       "34                                                NaN           NaN   \n",
       "35                                                NaN           NaN   \n",
       "36                                                NaN           NaN   \n",
       "37                                                NaN           NaN   \n",
       "38                                                NaN           NaN   \n",
       "39                                                NaN           NaN   \n",
       "40                                                NaN           NaN   \n",
       "41                                                NaN           NaN   \n",
       "42                                                NaN           NaN   \n",
       "43                                                NaN           NaN   \n",
       "44                                                NaN           NaN   \n",
       "45                                                NaN           NaN   \n",
       "46                                                NaN           NaN   \n",
       "47                                                NaN           NaN   \n",
       "48                                                NaN           NaN   \n",
       "49                                                NaN           NaN   \n",
       "50                                                NaN           NaN   \n",
       "51                                                NaN           NaN   \n",
       "52                                                NaN           NaN   \n",
       "53                                                NaN           NaN   \n",
       "54                                                NaN           NaN   \n",
       "55                                                NaN           NaN   \n",
       "56                                                NaN           NaN   \n",
       "57                                                NaN           NaN   \n",
       "58  [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [1566...       18.2907   \n",
       "\n",
       "    eval_samples_per_second  eval_steps_per_second  \n",
       "0                       NaN                    NaN  \n",
       "1                       NaN                    NaN  \n",
       "2                       NaN                    NaN  \n",
       "3                       NaN                    NaN  \n",
       "4                       NaN                    NaN  \n",
       "5                       NaN                    NaN  \n",
       "6                       NaN                    NaN  \n",
       "7                       NaN                    NaN  \n",
       "8                       NaN                    NaN  \n",
       "9                       NaN                    NaN  \n",
       "10                      NaN                    NaN  \n",
       "11                      NaN                    NaN  \n",
       "12                      NaN                    NaN  \n",
       "13                      NaN                    NaN  \n",
       "14                      NaN                    NaN  \n",
       "15                      NaN                    NaN  \n",
       "16                      NaN                    NaN  \n",
       "17                      NaN                    NaN  \n",
       "18                      NaN                    NaN  \n",
       "19                      NaN                    NaN  \n",
       "20                      NaN                    NaN  \n",
       "21                      NaN                    NaN  \n",
       "22                      NaN                    NaN  \n",
       "23                      NaN                    NaN  \n",
       "24                      NaN                    NaN  \n",
       "25                      NaN                    NaN  \n",
       "26                      NaN                    NaN  \n",
       "27                      NaN                    NaN  \n",
       "28                      NaN                    NaN  \n",
       "29                      NaN                    NaN  \n",
       "30                      NaN                    NaN  \n",
       "31                      NaN                    NaN  \n",
       "32                      NaN                    NaN  \n",
       "33                      NaN                    NaN  \n",
       "34                      NaN                    NaN  \n",
       "35                      NaN                    NaN  \n",
       "36                      NaN                    NaN  \n",
       "37                      NaN                    NaN  \n",
       "38                      NaN                    NaN  \n",
       "39                      NaN                    NaN  \n",
       "40                      NaN                    NaN  \n",
       "41                      NaN                    NaN  \n",
       "42                      NaN                    NaN  \n",
       "43                      NaN                    NaN  \n",
       "44                      NaN                    NaN  \n",
       "45                      NaN                    NaN  \n",
       "46                      NaN                    NaN  \n",
       "47                      NaN                    NaN  \n",
       "48                      NaN                    NaN  \n",
       "49                      NaN                    NaN  \n",
       "50                      NaN                    NaN  \n",
       "51                      NaN                    NaN  \n",
       "52                      NaN                    NaN  \n",
       "53                      NaN                    NaN  \n",
       "54                      NaN                    NaN  \n",
       "55                      NaN                    NaN  \n",
       "56                      NaN                    NaN  \n",
       "57                      NaN                    NaN  \n",
       "58                   16.402                  1.039  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_log = pd.DataFrame(trainer.state.log_history)\n",
    "display(training_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapter_location = '/models/testing_1'\n",
    "# training_log['eval_confusion_matrix'] = training_log['eval_confusion_matrix'].apply(lambda x: x.tolist() if type(x)==np.ndarray else None)\n",
    "# t5_lora_model.save_pretrained(ROOT + adapter_location)\n",
    "# training_log.to_csv(ROOT + adapter_location + '/training_log.csv', index=False)\n",
    "# training_log.to_parquet(ROOT + adapter_location + '/training_log.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iput IDs:\t M A A V I L E R L G A L W V Q N L R G K L A L G I L P Q S H I H T S A S L E I S R K W E K K N K I V Y P P Q L P G E P R R P A E I Y H C R R\n",
      "Labels:\t\t 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -100\n",
      "Labels Decoded:\t I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I\n",
      "Attention Mask:\t 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "----\n",
      "tensor(-0.9441, device='cuda:0') tensor(1.1183, device='cuda:0')\n",
      "Result: \t M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M M\n"
     ]
    }
   ],
   "source": [
    "_ds_index = 2\n",
    "_ds_type = 'test'\n",
    "\n",
    "_input_ids_test = t5_tokenizer.decode(dataset_signalp[_ds_type][_ds_index]['input_ids'][:-1])\n",
    "_labels_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['labels'] + [-100]]).to(device)\n",
    "_attention_mask_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['attention_mask']]).to(device)\n",
    "\n",
    "_labels_test_decoded = [src.config.label_decoding[x] for x in _labels_test.tolist()[0][:-1]]\n",
    "\n",
    "print('Iput IDs:\\t', _input_ids_test)\n",
    "print('Labels:\\t\\t', *_labels_test.tolist()[0])\n",
    "print('Labels Decoded:\\t', *_labels_test_decoded)\n",
    "print('Attention Mask:\\t', *_attention_mask_test.tolist()[0])\n",
    "print('----')\n",
    "\n",
    "preds = src.model_new.predict_model(\n",
    "    sequence=_input_ids_test,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    model=t5_lora_model,\n",
    "    labels=_labels_test,\n",
    "    attention_mask=_attention_mask_test,\n",
    "    device=device,\n",
    "    viterbi_decoding=use_crf,\n",
    "    )\n",
    "\n",
    "_result = src.model_new.translate_logits(\n",
    "    logits=preds.logits,\n",
    "    viterbi_decoding=use_crf,\n",
    "    )\n",
    "\n",
    "print('Result: \\t',* _result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_printoptions(threshold=10_000)\n",
    "# t5_lora_model.custom_classifier.modules_to_save.default.weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
