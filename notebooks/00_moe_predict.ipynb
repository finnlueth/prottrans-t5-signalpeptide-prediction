{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Base Model:\t Rostlab/prot_t5_xl_uniref50\n",
      "MPS:\t\t False\n",
      "Path:\t\t /home/ec2-user/developer/prottrans-t5-signalpeptide-prediction\n",
      "Using device:\t cuda:0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "from src.model_new import (\n",
    "    T5EncoderModelForTokenClassification,\n",
    "    T5EncoderModelForSequenceClassification,\n",
    "    create_datasets,\n",
    ")\n",
    "import src.config\n",
    "import src.data\n",
    "import src.model_new\n",
    "\n",
    "\n",
    "import peft\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel\n",
    ")\n",
    "\n",
    "import random\n",
    "\n",
    "ROOT = src.utils.get_project_root_path()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "\n",
    "USE_CRF = True\n",
    "EXPERT = 'ALL'\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Base Model:\\t\", src.config.base_model_name)\n",
    "print(\"MPS:\\t\\t\", torch.backends.mps.is_available())\n",
    "print(\"Path:\\t\\t\", ROOT)\n",
    "print(f\"Using device:\\t {device}\")\n",
    "\n",
    "# torch.set_printoptions(threshold=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=src.config.base_model_name,\n",
    "        do_lower_case=False,\n",
    "        use_fast=True,\n",
    "        legacy=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5EncoderModelForSequenceClassification were not initialized from the model checkpoint at Rostlab/prot_t5_xl_uniref50 and are newly initialized: ['custom_classifier_out.bias', 'custom_classifier_in.bias', 'custom_classifier_in.weight', 'custom_classifier_out.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "t5_base_model_gate = T5EncoderModelForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=src.config.base_model_name,\n",
    "    device_map='auto',\n",
    "    load_in_8bit=False,\n",
    "    custom_num_labels=len(src.config.type_encoding),\n",
    "    custom_dropout_rate=0.1,\n",
    "    use_crf=USE_CRF\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5EncoderModelForTokenClassification were not initialized from the model checkpoint at Rostlab/prot_t5_xl_uniref50 and are newly initialized: ['custom_classifier.bias', 'custom_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "t5_base_model_expert = T5EncoderModelForTokenClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=src.config.base_model_name,\n",
    "    device_map='auto',\n",
    "    load_in_8bit=False,\n",
    "    custom_num_labels=len(src.config.label_decoding),\n",
    "    custom_dropout_rate=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_location = '/models/moe_v1_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_adapter_location = adapter_location+'gate'\n",
    "t5_base_model_gate.load_adapter(ROOT+gate_adapter_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 12462\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4149\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4147\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FASTA_FILENAME = '5_SignalP_5.0_Training_set.fasta'\n",
    "# FASTA_FILENAME = '5_SignalP_5.0_Training_set_testing.fasta'\n",
    "annotations_name = 'Label' # Choose Type or Label\n",
    "\n",
    "df_data = src.data.process(src.data.parse_file(ROOT + '/data/raw/' + FASTA_FILENAME))\n",
    "\n",
    "dataset_signalp_type_splits = {}\n",
    "\n",
    "dataset_signalp_type_splits.update(\n",
    "    {'ALL': src.model_new.create_datasets(\n",
    "        splits=src.config.splits,\n",
    "        tokenizer=t5_tokenizer,\n",
    "        data=df_data,\n",
    "        annotations_name=annotations_name,\n",
    "        dataset_size=src.config.dataset_size,\n",
    "        encoder=src.config.label_encoding,\n",
    "    )})\n",
    "\n",
    "for sequence_type in src.config.type_encoding.keys():\n",
    "    dataset_signalp = src.model_new.create_datasets(\n",
    "        splits=src.config.splits,\n",
    "        tokenizer=t5_tokenizer,\n",
    "        data=df_data,\n",
    "        annotations_name=annotations_name,\n",
    "        dataset_size=src.config.dataset_size,\n",
    "        encoder=src.config.select_encoding_type[sequence_type],\n",
    "        sequence_type=sequence_type\n",
    "        )\n",
    "    dataset_signalp_type_splits.update({sequence_type: dataset_signalp})\n",
    "\n",
    "del df_data\n",
    "\n",
    "dataset_signalp = dataset_signalp_type_splits[EXPERT]\n",
    "display(dataset_signalp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m _labels_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([dataset_signalp[_ds_type][_ds_index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m _attention_mask_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([dataset_signalp[_ds_type][_ds_index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m _labels_test_decoded \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_decoding\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_labels_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m _labels_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([dataset_signalp[_ds_type][_ds_index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m _attention_mask_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([dataset_signalp[_ds_type][_ds_index][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m _labels_test_decoded \u001b[38;5;241m=\u001b[39m [\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_decoding\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m _labels_test\u001b[38;5;241m.\u001b[39mtolist()]\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "_ds_index = 0\n",
    "_ds_type = 'test'\n",
    "\n",
    "_input_ids_test = t5_tokenizer.decode(dataset_signalp[_ds_type][_ds_index]['input_ids'][:-1])\n",
    "_labels_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['labels']]).to(device)\n",
    "_attention_mask_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['attention_mask']]).to(device)\n",
    "\n",
    "_labels_test_decoded = [src.config.type_decoding[x] for x in _labels_test.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.model_new.moe_inference(\n",
    "    sequence=_input_ids_test,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    model_gate=t5_base_model_gate,\n",
    "    model_expert=t5_base_model_gate,\n",
    "    labels=_labels_test,\n",
    "    attention_mask=_attention_mask_test,\n",
    "    device=device,\n",
    "    result_type='NO_SP'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading adapter weights from /home/ec2-user/developer/prottrans-t5-signalpeptide-prediction/models/moe_v1_expert_ALL led to unexpected keys not found in the model:  ['crf.start_transitions', 'crf.end_transitions', 'crf.transitions']. \n"
     ]
    }
   ],
   "source": [
    "expert_adapter_location = adapter_location+'expert_'+EXPERT\n",
    "t5_base_model_expert.load_adapter(ROOT+expert_adapter_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iput IDs:\t M D F L H R N G V L I I Q H L Q K D Y R A Y Y T F L N F M S N V G D P R N I F F I Y F P L C F Q F N Q T V G T K M I W V A V I G D W L N L I\n",
      "Labels:\t\t 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 -100\n",
      "Labels Decoded:\t O O O O O O O O O O O O O O O O O O O O O O O O M M M M M M M M M M M M M M M M M M M M M I I I I I I I I I I I M M M M M M M M M M M M M M\n",
      "Attention Mask:\t 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "----\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'T5EncoderModelForTokenClassification' object has no attribute 'crf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttention Mask:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m_attention_mask_test\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_new\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_input_ids_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt5_tokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt5_base_model_expert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_labels_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attention_mask_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mviterbi_decoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUSE_CRF\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m _result \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mmodel_new\u001b[38;5;241m.\u001b[39mtranslate_logits(\n\u001b[1;32m     29\u001b[0m     logits\u001b[38;5;241m=\u001b[39mpreds\u001b[38;5;241m.\u001b[39mlogits,\n\u001b[1;32m     30\u001b[0m     viterbi_decoding\u001b[38;5;241m=\u001b[39mUSE_CRF,\n\u001b[1;32m     31\u001b[0m     decoding\u001b[38;5;241m=\u001b[39msrc\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlabel_decoding\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult: \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m*\u001b[39m _result)\n",
      "File \u001b[0;32m~/developer/prottrans-t5-signalpeptide-prediction/src/model_new.py:318\u001b[0m, in \u001b[0;36mpredict_model\u001b[0;34m(sequence, tokenizer, model, attention_mask, labels, device, viterbi_decoding)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# print(tokenized_string.shape)\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# print(labels.shape)\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# print(attention_mask.shape)\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 318\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_string\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mviterbi_decoding\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/developer/prottrans-t5-signalpeptide-prediction/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/developer/prottrans-t5-signalpeptide-prediction/src/model_new.py:111\u001b[0m, in \u001b[0;36mT5EncoderModelForTokenClassification.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    108\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mlog_likelihood\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;66;03m# print('neglog_likelihood', loss)\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         decoded_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrf\u001b[49m\u001b[38;5;241m.\u001b[39mmodules_to_save\u001b[38;5;241m.\u001b[39mdefault\u001b[38;5;241m.\u001b[39mdecode(logits, mask\u001b[38;5;241m=\u001b[39mattention_mask\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39muint8))\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/developer/prottrans-t5-signalpeptide-prediction/.venv/lib64/python3.11/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'T5EncoderModelForTokenClassification' object has no attribute 'crf'"
     ]
    }
   ],
   "source": [
    "# _ds_index = 3250\n",
    "_ds_index = 3250\n",
    "_ds_type = 'test'\n",
    "USE_CRF = True\n",
    "\n",
    "_input_ids_test = t5_tokenizer.decode(dataset_signalp[_ds_type][_ds_index]['input_ids'][:-1])\n",
    "_labels_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['labels'] + [-100]]).to(device)\n",
    "_attention_mask_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['attention_mask']]).to(device)\n",
    "\n",
    "_labels_test_decoded = [src.config.label_decoding[x] for x in _labels_test.tolist()[0][:-1]]\n",
    "\n",
    "print('Iput IDs:\\t', _input_ids_test)\n",
    "print('Labels:\\t\\t', *_labels_test.tolist()[0])\n",
    "print('Labels Decoded:\\t', *_labels_test_decoded)\n",
    "print('Attention Mask:\\t', *_attention_mask_test.tolist()[0])\n",
    "print('----')\n",
    "\n",
    "preds = src.model_new.predict_model(\n",
    "    sequence=_input_ids_test,\n",
    "    tokenizer=t5_tokenizer,\n",
    "    model=t5_base_model_expert,\n",
    "    labels=_labels_test,\n",
    "    attention_mask=_attention_mask_test,\n",
    "    device=device,\n",
    "    viterbi_decoding=USE_CRF,\n",
    "    )\n",
    "\n",
    "_result = src.model_new.translate_logits(\n",
    "    logits=preds.logits,\n",
    "    viterbi_decoding=USE_CRF,\n",
    "    decoding=src.config.label_decoding\n",
    "    )\n",
    "\n",
    "print('Result: \\t',* _result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
