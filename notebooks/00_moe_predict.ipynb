{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "from src.model_new import (\n",
    "    T5EncoderModelForTokenClassification,\n",
    "    T5EncoderModelForSequenceClassification,\n",
    "    create_datasets,\n",
    ")\n",
    "import src.config\n",
    "import src.data\n",
    "import src.model_new\n",
    "\n",
    "\n",
    "import peft\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel\n",
    ")\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model:\t Rostlab/prot_t5_xl_uniref50\n",
      "MPS:\t\t False\n",
      "Path:\t\t /home/ec2-user/developer/prottrans-t5-signalpeptide-prediction\n",
      "Using device:\t cuda:0\n",
      "Using CRF\t\t False\n"
     ]
    }
   ],
   "source": [
    "ROOT = src.utils.get_project_root_path()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu'))\n",
    "\n",
    "\n",
    "EXPERT = 'NO_SP'\n",
    "MODEL_VERRSION = src.config.model_version\n",
    "MODEL = 'linear'\n",
    "adapter_location = f'/models/moe_v{MODEL_VERRSION}_'\n",
    "\n",
    "USE_CRF = MODEL == 'crf'\n",
    "SEED = 42\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Base Model:\\t\", src.config.base_model_name)\n",
    "print(\"MPS:\\t\\t\", torch.backends.mps.is_available())\n",
    "print(\"Path:\\t\\t\", ROOT)\n",
    "print(f\"Using device:\\t {device}\")\n",
    "print('Using CRF\\t\\t', USE_CRF)\n",
    "\n",
    "# torch.set_printoptions(threshold=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained(\n",
    "        pretrained_model_name_or_path=src.config.base_model_name,\n",
    "        do_lower_case=False,\n",
    "        use_fast=True,\n",
    "        legacy=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASTA_FILENAME = '5_SignalP_5.0_Training_set.fasta'\n",
    "# # FASTA_FILENAME = '5_SignalP_5.0_Training_set_testing.fasta'\n",
    "# annotations_name = ['Label'] + ['Type'] # Choose Type or Label\n",
    "\n",
    "# df_data = src.data.process(src.data.parse_file(ROOT + '/data/raw/' + FASTA_FILENAME))\n",
    "\n",
    "# dataset_signalp_type_splits = {}\n",
    "\n",
    "# for sequence_type in src.config.select_encoding_type.keys():\n",
    "#     dataset_signalp = src.model_new.create_datasets(\n",
    "#         splits=src.config.splits,\n",
    "#         tokenizer=t5_tokenizer,\n",
    "#         data=df_data,\n",
    "#         annotations_name=annotations_name,\n",
    "#         dataset_size=src.config.dataset_size,\n",
    "#         sequence_type=sequence_type\n",
    "#         )\n",
    "#     dataset_signalp_type_splits.update({sequence_type: dataset_signalp})\n",
    "\n",
    "# del df_data\n",
    "\n",
    "# dataset_signalp = dataset_signalp_type_splits[EXPERT]\n",
    "# display(dataset_signalp_type_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5_base_model_gate = T5EncoderModelForSequenceClassification.from_pretrained(\n",
    "#     pretrained_model_name_or_path=src.config.base_model_name,\n",
    "#     device_map='auto',\n",
    "#     load_in_8bit=False,\n",
    "#     custom_num_labels=len(src.config.type_encoding),\n",
    "#     custom_dropout_rate=0.1,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(src.config.label_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 0, 'M': 1, 'O': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.config.select_encoding_type[EXPERT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5EncoderModelForTokenClassification were not initialized from the model checkpoint at Rostlab/prot_t5_xl_uniref50 and are newly initialized: ['custom_classifier.bias', 'custom_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "t5_base_model_expert = T5EncoderModelForTokenClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=src.config.base_model_name,\n",
    "    device_map='auto',\n",
    "    load_in_8bit=False,\n",
    "    custom_num_labels=len(src.config.select_encoding_type[EXPERT]),\n",
    "    custom_dropout_rate=0.1,\n",
    "    use_crf=USE_CRF\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate_adapter_location = adapter_location+'gate'\n",
    "# t5_base_model_gate.load_adapter(ROOT+gate_adapter_location, adapter_name=f\"gate\")\n",
    "# t5_base_model_gate.set_adapter(\"gate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/models/moe_v1_linear_expert_NO_SP adapter_NO_SP\n"
     ]
    }
   ],
   "source": [
    "expert_adapter_location = adapter_location+f'{MODEL}_expert_{EXPERT}'\n",
    "adapter_name = f\"adapter_{EXPERT}\"\n",
    "print(expert_adapter_location, adapter_name)\n",
    "t5_base_model_expert.load_adapter(ROOT+expert_adapter_location, adapter_name=adapter_name)\n",
    "t5_base_model_expert.set_adapter(adapter_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "todo\n",
    "\n",
    "X gate\\\n",
    "X lin all\\\n",
    "X lin expert\\\n",
    "X crf all \\\n",
    "O crf expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASTA_FILENAME = '5_SignalP_5.0_Training_set.fasta'\n",
    "# df_data = src.data.process(src.data.parse_file(ROOT + '/data/raw/' + FASTA_FILENAME))\n",
    "# df_data = df_data[df_data['Partition_No'] == 4].reset_index(drop=True)\n",
    "# df_data['Sequence_Raw'] = df_data['Sequence'].apply(lambda x: x.replace(' ', ''))\n",
    "# # df_data['Mask'] = [x[1:] for x in dataset_signalp_type_splits['ALL']['test']['attention_mask']]\n",
    "# df_data['input_ids'] = dataset_signalp_type_splits['ALL']['test']['input_ids']\n",
    "# df_data['ds_attention_mask'] = dataset_signalp_type_splits['ALL']['test']['attention_mask']\n",
    "# df_data['ds_labels'] = dataset_signalp_type_splits['ALL']['test']['labels']\n",
    "# df_data['ds_type'] = dataset_signalp_type_splits['ALL']['test']['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_parquet('./results/df_data.parquet.gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot_AC</th>\n",
       "      <th>Kingdom</th>\n",
       "      <th>Type</th>\n",
       "      <th>Partition_No</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sequence_Raw</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>ds_attention_mask</th>\n",
       "      <th>ds_labels</th>\n",
       "      <th>ds_type</th>\n",
       "      <th>predicted_type</th>\n",
       "      <th>predicted_label_linear_ALL</th>\n",
       "      <th>predicted_label_linear_experts</th>\n",
       "      <th>predicted_label_crf_ALL</th>\n",
       "      <th>predicted_label_crf_experts</th>\n",
       "      <th>predicted_label_linear_experts_imperfect_viterbi</th>\n",
       "      <th>predicted_label_crf_experts_imperfect</th>\n",
       "      <th>predicted_label_linear_experts_imperfect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P55317</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>4</td>\n",
       "      <td>M L G T V K M E G H E T S D W N S Y Y A D T Q ...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>MLGTVKMEGHETSDWNSYYADTQEAYSSVPVSNMNSGLGSMNSMNT...</td>\n",
       "      <td>[19, 4, 5, 11, 6, 14, 19, 9, 5, 20, 9, 11, 7, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P35583</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>4</td>\n",
       "      <td>M L G A V K M E G H E P S D W S S Y Y A E P E ...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>MLGAVKMEGHEPSDWSSYYAEPEGYSSVSNMNAGLGMNGMNTYMSM...</td>\n",
       "      <td>[19, 4, 5, 3, 6, 14, 19, 9, 5, 20, 9, 13, 7, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q8UVD9</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>4</td>\n",
       "      <td>M E I S T P D F G F G T E D S S A Q Q S A N R ...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>MEISTPDFGFGTEDSSAQQSANRAIPQPVPAPAFPLKETASDTGGT...</td>\n",
       "      <td>[19, 9, 12, 7, 11, 13, 10, 15, 5, 15, 5, 11, 9...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q99PF5</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>4</td>\n",
       "      <td>M S D Y S T G G P P P G P P P P A G G G G G A ...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>MSDYSTGGPPPGPPPPAGGGGGAAGAGGGPPPGPPGAGDRGGGGPG...</td>\n",
       "      <td>[19, 7, 10, 18, 7, 11, 5, 5, 13, 13, 13, 5, 13...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q9URU9</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>4</td>\n",
       "      <td>M N F R P E Q Q Y I L E K P G I L L S F E Q L ...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>MNFRPEQQYILEKPGILLSFEQLRINFKHILRHLEHESHVINSTLT...</td>\n",
       "      <td>[19, 17, 15, 8, 13, 9, 16, 16, 18, 12, 4, 9, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Uniprot_AC  Kingdom   Type  Partition_No  \\\n",
       "0     P55317  EUKARYA  NO_SP             4   \n",
       "1     P35583  EUKARYA  NO_SP             4   \n",
       "2     Q8UVD9  EUKARYA  NO_SP             4   \n",
       "3     Q99PF5  EUKARYA  NO_SP             4   \n",
       "4     Q9URU9  EUKARYA  NO_SP             4   \n",
       "\n",
       "                                            Sequence  \\\n",
       "0  M L G T V K M E G H E T S D W N S Y Y A D T Q ...   \n",
       "1  M L G A V K M E G H E P S D W S S Y Y A E P E ...   \n",
       "2  M E I S T P D F G F G T E D S S A Q Q S A N R ...   \n",
       "3  M S D Y S T G G P P P G P P P P A G G G G G A ...   \n",
       "4  M N F R P E Q Q Y I L E K P G I L L S F E Q L ...   \n",
       "\n",
       "                                               Label  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "                                        Sequence_Raw  \\\n",
       "0  MLGTVKMEGHETSDWNSYYADTQEAYSSVPVSNMNSGLGSMNSMNT...   \n",
       "1  MLGAVKMEGHEPSDWSSYYAEPEGYSSVSNMNAGLGMNGMNTYMSM...   \n",
       "2  MEISTPDFGFGTEDSSAQQSANRAIPQPVPAPAFPLKETASDTGGT...   \n",
       "3  MSDYSTGGPPPGPPPPAGGGGGAAGAGGGPPPGPPGAGDRGGGGPG...   \n",
       "4  MNFRPEQQYILEKPGILLSFEQLRINFKHILRHLEHESHVINSTLT...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [19, 4, 5, 11, 6, 14, 19, 9, 5, 20, 9, 11, 7, ...   \n",
       "1  [19, 4, 5, 3, 6, 14, 19, 9, 5, 20, 9, 13, 7, 1...   \n",
       "2  [19, 9, 12, 7, 11, 13, 10, 15, 5, 15, 5, 11, 9...   \n",
       "3  [19, 7, 10, 18, 7, 11, 5, 5, 13, 13, 13, 5, 13...   \n",
       "4  [19, 17, 15, 8, 13, 9, 16, 16, 18, 12, 4, 9, 1...   \n",
       "\n",
       "                                   ds_attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                           ds_labels  ds_type predicted_type  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0          NO_SP   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0          NO_SP   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0          NO_SP   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0          NO_SP   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0          NO_SP   \n",
       "\n",
       "                          predicted_label_linear_ALL  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "                      predicted_label_linear_experts  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "                             predicted_label_crf_ALL  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "                         predicted_label_crf_experts  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "    predicted_label_linear_experts_imperfect_viterbi  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "               predicted_label_crf_experts_imperfect  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "  predicted_label_linear_experts_imperfect  \n",
       "0                                     None  \n",
       "1                                     None  \n",
       "2                                     None  \n",
       "3                                     None  \n",
       "4                                     None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4147, 19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(dataset_signalp_type_splits['ALL']['test'])\n",
    "display(df_data.head(), df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data['predicted_type'] = df_data.progress_apply(lambda x:\n",
    "#     src.model_new.translate_logits(\n",
    "#         src.model_new.predict_model(\n",
    "#             sequence=x['Sequence'],\n",
    "#             tokenizer=t5_tokenizer,\n",
    "#             model=t5_base_model_gate,\n",
    "#             attention_mask=torch.Tensor([x['ds_attention_mask']]).to(device),\n",
    "#             device=device\n",
    "#             )['logits'].unsqueeze(0),\n",
    "#         src.config.type_decoding,\n",
    "#         viterbi_decoding=False\n",
    "#         )[0],  axis=1\n",
    "#     )\n",
    "# display(df_data.head())\n",
    "# df_data.to_parquet('./results/df_data.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_df = df_data.tail(700).copy(deep=True)\n",
    "\n",
    "# df_data[f'predicted_label_crf_{EXPERT}'] = df_data.progress_apply(lambda x:\n",
    "#     ''.join(src.model_new.translate_logits(\n",
    "#         src.model_new.predict_model(\n",
    "#             sequence=x['Sequence'],\n",
    "#             tokenizer=t5_tokenizer,\n",
    "#             model=t5_base_model_expert,\n",
    "#             attention_mask=torch.Tensor([x['ds_attention_mask']]).to(device),\n",
    "#             device=device\n",
    "#             )['logits'],\n",
    "#         src.config.select_decoding_type[EXPERT],\n",
    "#         viterbi_decoding=USE_CRF\n",
    "#         ))[:np.count_nonzero(x['ds_attention_mask'])-1],  axis=1\n",
    "#     )\n",
    "# display(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4147 [00:00<?, ?it/s]/tmp/ipykernel_10685/1408454751.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  attention_mask=torch.Tensor([x['ds_attention_mask']]).to(device),\n",
      "100%|██████████| 4147/4147 [03:20<00:00, 20.69it/s] \n"
     ]
    }
   ],
   "source": [
    "# test_df = df_data.tail(20).copy(deep=True)\n",
    "column_name = 'predicted_label_linear_experts_imperfect'\n",
    "\n",
    "df_data[column_name] = df_data.progress_apply(lambda x:\n",
    "    ''.join(src.model_new.translate_logits(\n",
    "        src.model_new.predict_model(\n",
    "            sequence=x['Sequence'],\n",
    "            tokenizer=t5_tokenizer,\n",
    "            model=t5_base_model_expert,\n",
    "            attention_mask=torch.Tensor([x['ds_attention_mask']]).to(device),\n",
    "            device=device\n",
    "            )['logits'],\n",
    "        src.config.select_decoding_type[EXPERT],\n",
    "        viterbi_decoding=USE_CRF\n",
    "        ))[:np.count_nonzero(x['ds_attention_mask'])-1] if x['predicted_type'] == EXPERT else x[column_name],  axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniprot_AC</th>\n",
       "      <th>Kingdom</th>\n",
       "      <th>Type</th>\n",
       "      <th>Partition_No</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sequence_Raw</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>ds_attention_mask</th>\n",
       "      <th>ds_labels</th>\n",
       "      <th>ds_type</th>\n",
       "      <th>predicted_type</th>\n",
       "      <th>predicted_label_linear_ALL</th>\n",
       "      <th>predicted_label_linear_experts</th>\n",
       "      <th>predicted_label_crf_ALL</th>\n",
       "      <th>predicted_label_crf_experts</th>\n",
       "      <th>predicted_label_linear_experts_imperfect_viterbi</th>\n",
       "      <th>predicted_label_crf_experts_imperfect</th>\n",
       "      <th>predicted_label_linear_experts_imperfect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P55317</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>4</td>\n",
       "      <td>M L G T V K M E G H E T S D W N S Y Y A D T Q ...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>MLGTVKMEGHETSDWNSYYADTQEAYSSVPVSNMNSGLGSMNSMNT...</td>\n",
       "      <td>[19, 4, 5, 11, 6, 14, 19, 9, 5, 20, 9, 11, 7, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P35583</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>4</td>\n",
       "      <td>M L G A V K M E G H E P S D W S S Y Y A E P E ...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>MLGAVKMEGHEPSDWSSYYAEPEGYSSVSNMNAGLGMNGMNTYMSM...</td>\n",
       "      <td>[19, 4, 5, 3, 6, 14, 19, 9, 5, 20, 9, 13, 7, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q8UVD9</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>4</td>\n",
       "      <td>M E I S T P D F G F G T E D S S A Q Q S A N R ...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>MEISTPDFGFGTEDSSAQQSANRAIPQPVPAPAFPLKETASDTGGT...</td>\n",
       "      <td>[19, 9, 12, 7, 11, 13, 10, 15, 5, 15, 5, 11, 9...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q99PF5</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>4</td>\n",
       "      <td>M S D Y S T G G P P P G P P P P A G G G G G A ...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>MSDYSTGGPPPGPPPPAGGGGGAAGAGGGPPPGPPGAGDRGGGGPG...</td>\n",
       "      <td>[19, 7, 10, 18, 7, 11, 5, 5, 13, 13, 13, 5, 13...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q9URU9</td>\n",
       "      <td>EUKARYA</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>4</td>\n",
       "      <td>M N F R P E Q Q Y I L E K P G I L L S F E Q L ...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>MNFRPEQQYILEKPGILLSFEQLRINFKHILRHLEHESHVINSTLT...</td>\n",
       "      <td>[19, 17, 15, 8, 13, 9, 16, 16, 18, 12, 4, 9, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NO_SP</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "      <td>IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Uniprot_AC  Kingdom   Type  Partition_No  \\\n",
       "0     P55317  EUKARYA  NO_SP             4   \n",
       "1     P35583  EUKARYA  NO_SP             4   \n",
       "2     Q8UVD9  EUKARYA  NO_SP             4   \n",
       "3     Q99PF5  EUKARYA  NO_SP             4   \n",
       "4     Q9URU9  EUKARYA  NO_SP             4   \n",
       "\n",
       "                                            Sequence  \\\n",
       "0  M L G T V K M E G H E T S D W N S Y Y A D T Q ...   \n",
       "1  M L G A V K M E G H E P S D W S S Y Y A E P E ...   \n",
       "2  M E I S T P D F G F G T E D S S A Q Q S A N R ...   \n",
       "3  M S D Y S T G G P P P G P P P P A G G G G G A ...   \n",
       "4  M N F R P E Q Q Y I L E K P G I L L S F E Q L ...   \n",
       "\n",
       "                                               Label  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "                                        Sequence_Raw  \\\n",
       "0  MLGTVKMEGHETSDWNSYYADTQEAYSSVPVSNMNSGLGSMNSMNT...   \n",
       "1  MLGAVKMEGHEPSDWSSYYAEPEGYSSVSNMNAGLGMNGMNTYMSM...   \n",
       "2  MEISTPDFGFGTEDSSAQQSANRAIPQPVPAPAFPLKETASDTGGT...   \n",
       "3  MSDYSTGGPPPGPPPPAGGGGGAAGAGGGPPPGPPGAGDRGGGGPG...   \n",
       "4  MNFRPEQQYILEKPGILLSFEQLRINFKHILRHLEHESHVINSTLT...   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [19, 4, 5, 11, 6, 14, 19, 9, 5, 20, 9, 11, 7, ...   \n",
       "1  [19, 4, 5, 3, 6, 14, 19, 9, 5, 20, 9, 13, 7, 1...   \n",
       "2  [19, 9, 12, 7, 11, 13, 10, 15, 5, 15, 5, 11, 9...   \n",
       "3  [19, 7, 10, 18, 7, 11, 5, 5, 13, 13, 13, 5, 13...   \n",
       "4  [19, 17, 15, 8, 13, 9, 16, 16, 18, 12, 4, 9, 1...   \n",
       "\n",
       "                                   ds_attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                           ds_labels  ds_type predicted_type  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0          NO_SP   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0          NO_SP   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0          NO_SP   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0          NO_SP   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        0          NO_SP   \n",
       "\n",
       "                          predicted_label_linear_ALL  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "                      predicted_label_linear_experts  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "                             predicted_label_crf_ALL  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "                         predicted_label_crf_experts  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "    predicted_label_linear_experts_imperfect_viterbi  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "               predicted_label_crf_experts_imperfect  \\\n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...   \n",
       "\n",
       "            predicted_label_linear_experts_imperfect  \n",
       "0  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...  \n",
       "1  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...  \n",
       "2  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...  \n",
       "3  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...  \n",
       "4  IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4147, 19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_data.head(), df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((267,),\n",
       " predicted_label_linear_experts_imperfect\n",
       " IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII    2802\n",
       " IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIM       5\n",
       " IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII          4\n",
       " IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIMMMMMMMMMMMMMMMMMMOIIII       2\n",
       " IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII                     2\n",
       "                                                                           ... \n",
       " IIIIIMMMMMMMMMMIMMIIIIIIIIIIIIIIIIIIIMMIMMMMMMMMMMMMIMIIIIIIIIIIIIIIII       1\n",
       " IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIMMMMMMMMMMMMMMMMMMIIIII       1\n",
       " IIIIIIIIIIIMIMMMMMMMMIIMIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII       1\n",
       " IIIIIIIIIIIIIIIIIIIIIMMMMMMMMMMMMMMMMMMMMIIIIIIIIIIOIIIIIIIIIIIIIIIIII       1\n",
       " IIIIIIIOIIIIIIIOIIIIIIIIIOIIIIOIIIIOIIOOOOIMMIOIMMMMMMMMMMMMMMMMIMMMII       1\n",
       " Name: count, Length: 267, dtype: int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect = df_data[df_data['predicted_type'] == EXPERT]\n",
    "inspect[column_name].value_counts().shape, inspect[column_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_data[column_name].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df[test_df['Sequence_Raw'].str.len() != 70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc = 3458\n",
    "# print(test_df['predicted_label_linear_ALL'].loc[loc], test_df['Label'].loc[loc])\n",
    "# print(test_df['predicted_label_linear_ALL'].loc[loc].__len__(), test_df['Label'].loc[loc].__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data[df_data['predicted_type'] != df_data['Type']]\n",
    "# t5_tokenizer.decode(t5_tokenizer.encode('M T E T L P P V T E S A V A L Q A E V T Q R E L F E F V L N D P L L A S S L Y I N I A L A G L S I L L F V F M T R G L D D P R A K L I A V S'))\n",
    "# dataset_signalp_type_splits['ALL']['test']['attention_mask']\n",
    "# decoded_shit = [(x, ''.join([t5_tokenizer.decode(z) for z in y])) for x, y in zip(df_data['Sequence'], dataset_signalp_type_splits['ALL']['test']['input_ids'])]\n",
    "# print(*decoded_shit, sep='\\n')\n",
    "# len(decoded_shit)\n",
    "# len(df_data['Sequence'].at[0]), len(df_data['Mask'].at[0])# print(*[(x, y) for x, y in zip(df_data['Sequence'], df_data['Mask'])], sep='\\n')\n",
    "#  df_singalp_split = df_singalp6_preds[\n",
    "#     df_singalp6_preds['Type'] == 'SP'\n",
    "# ]\n",
    "# test_df = df_data.head().copy(deep=True)\n",
    "# test_df\n",
    "# test_df['asd'] = test_df.apply(lambda x: (x['Type'], x['Mask']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data['predicted_label_linear_experts_imperfect'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = df_data.rename(columns={'predicted_label_linear_experts_imperfect': 'predicted_label_linear_experts_imperfect_viterbi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_parquet('./results/df_data.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context('display.max_rows', None,\n",
    "#                        'display.max_columns', None,\n",
    "#                        'display.precision', 3,\n",
    "#                        'display.max_colwidth', 100\n",
    "#                        ):\n",
    "#     display(df_data[[\n",
    "#         'Type',\n",
    "#         'predicted_type',\n",
    "#         'Label',\n",
    "#         'predicted_label_linear_ALL',\n",
    "#         'predicted_label_linear_experts',\n",
    "#         'predicted_label_crf_ALL',\n",
    "#         'predicted_label_crf_experts',\n",
    "#         'predicted_label_linear_experts_imperfect_viterbi',\n",
    "#         'predicted_label_crf_experts_imperfect',\n",
    "#         'predicted_label_linear_experts_imperfect'\n",
    "#         ]].tail(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expert_adapter_location = adapter_location + f'expert_{EXPERT}'\n",
    "# t5_base_model_expert.load_adapter(ROOT+expert_adapter_location)\n",
    "\n",
    "# FASTA_FILENAME = '5_SignalP_5.0_Training_set_testing.fasta'\n",
    "# df_data = src.data.process(src.data.parse_file(ROOT + '/data/raw/' + FASTA_FILENAME))\n",
    "# df_data = df_data[df_data['Partition_No'] == 4].reset_index(drop=True)\n",
    "# df_data['Sequence'] = df_data['Sequence'].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_data['Type_Prediction'] = \n",
    "# df_data['Label'].iloc[17:18].apply(lambda x: src.model_new.moe_inference(\n",
    "#     sequence=x,\n",
    "#     tokenizer=t5_tokenizer,\n",
    "#     model_gate=t5_base_model_gate,\n",
    "#     model_expert=t5_base_model_expert,\n",
    "#     device=device,\n",
    "#     # result_type='SP',\n",
    "#     )[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERT = 'LIPO'\n",
    "# expert_adapter_location = ROOT + adapter_location + f'expert_{EXPERT}'\n",
    "# print(expert_adapter_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5_base_model_expert.load_adapter(expert_adapter_location, adapter_name=f\"{EXPERT}_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5_base_model_expert.unload(EXPERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ds_index = 4\n",
    "# # _input_ids_test = df_data['Sequence'].iloc[_ds_index]\n",
    "# # _labels_test = df_data['Label'].iloc[_ds_index]\n",
    "# # _type_test = df_data['Type'].iloc[_ds_index]\n",
    "# _input_ids_test = t5_tokenizer.decode(dataset_signalp[_ds_type][_ds_index]['input_ids'][:-1])\n",
    "# _labels_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['labels'] + [-100]]).to(device)\n",
    "# _attention_mask_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['attention_mask']]).to(device)\n",
    "\n",
    "\n",
    "# print('Iput IDs:\\t', _input_ids_test)\n",
    "# print('Labels:\\t\\t', _labels_test)\n",
    "# print('Type:\\t\\t', _type_test)\n",
    "\n",
    "# result = src.model_new.moe_inference(\n",
    "#     sequence=_input_ids_test,\n",
    "#     attentino_mask=_attention_mask_test,\n",
    "#     tokenizer=t5_tokenizer,\n",
    "#     model_gate=t5_base_model_gate,\n",
    "#     model_expert=t5_base_model_expert,\n",
    "#     device=device,\n",
    "#     result_type='LIPO',\n",
    "#     use_crf=True,\n",
    "# )\n",
    "\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t5_base_model_gate.unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # _ds_index = 220\n",
    "# # _ds_type = 'test'\n",
    "# # USE_CRF = True\n",
    "\n",
    "# # _input_ids_test = t5_tokenizer.decode(dataset_signalp[_ds_type][_ds_index]['input_ids'][:-1])\n",
    "# # _labels_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['labels'] + [-100]]).to(device)\n",
    "# # _attention_mask_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['attention_mask']]).to(device)\n",
    "\n",
    "# # _labels_test_decoded = [src.config.label_decoding[x] for x in _labels_test.tolist()[0][:-1]]\n",
    "\n",
    "# # print('Iput IDs:\\t', _input_ids_test)\n",
    "# # print('Labels:\\t\\t', *_labels_test.tolist()[0])\n",
    "# # print('Labels Decoded:\\t', *_labels_test_decoded)\n",
    "# # print('Attention Mask:\\t', *_attention_mask_test.tolist()[0])\n",
    "# # print('----')\n",
    "\n",
    "# # _ds_index = 3250\n",
    "# _ds_index = 3250\n",
    "# _ds_type = 'test'\n",
    "# USE_CRF = True\n",
    "\n",
    "# _input_ids_test = t5_tokenizer.decode(dataset_signalp[_ds_type][_ds_index]['input_ids'][:-1])\n",
    "# _labels_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['labels'] + [-100]]).to(device)\n",
    "# _attention_mask_test = torch.tensor([dataset_signalp[_ds_type][_ds_index]['attention_mask']]).to(device)\n",
    "\n",
    "# _labels_test_decoded = [src.config.label_decoding[x] for x in _labels_test.tolist()[0][:-1]]\n",
    "\n",
    "# print('Iput IDs:\\t', _input_ids_test)\n",
    "# print('Labels:\\t\\t', *_labels_test.tolist()[0])\n",
    "# print('Labels Decoded:\\t', *_labels_test_decoded)\n",
    "# print('Attention Mask:\\t', *_attention_mask_test.tolist()[0])\n",
    "# print('----')\n",
    "\n",
    "# preds = src.model_new.predict_model(\n",
    "#     sequence=_input_ids_test,\n",
    "#     tokenizer=t5_tokenizer,\n",
    "#     model=t5_base_model_expert,\n",
    "#     labels=_labels_test,\n",
    "#     attention_mask=_attention_mask_test,\n",
    "#     device=device,\n",
    "#     viterbi_decoding=USE_CRF,\n",
    "#     )\n",
    "\n",
    "# _result = src.model_new.translate_logits(\n",
    "#     logits=preds.logits,\n",
    "#     viterbi_decoding=USE_CRF,\n",
    "#     decoding=src.config.label_decoding\n",
    "#     )\n",
    "\n",
    "# print('Result: \\t',* _result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
